{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating agent workflows: Customer Support\n",
    "\n",
    "A more advanced use case of LLM evaluation is measuring the response of conversational systems.\n",
    "\n",
    "This short cookbook sets up an customer support agent system and then shows a practical evaluation method using Braintrust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We'll have an LLM take the role of both the customer and the support agent, in this case.\n",
    "\n",
    "First, let's put together a customer support operating procedure and prompt, with relevant actions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "CUSTOMER_SUPPORT_AGENT_PROMPT = dedent(\n",
    "    \"\"\"\n",
    "    You are a reliable and friendly customer support agent named Viola, speaking to a customer.\n",
    "    You will attempt to assist the customer while complying with the company policies.\n",
    "\n",
    "    Company Policies:\n",
    "    Items can be exchanged within 60 days of purchase if they are defective. \n",
    "    Items can be returned within 30 days of purchase so long as they are in the same condition as when they were purchased.\n",
    "    Offer an exchange before offering a refund, but if the customer insists on a refund, you can process it.\n",
    "    If a situation is outside of the above, you can refuse a return or exchange.\n",
    "\n",
    "    You don't need any information from the customer to process refunds or exchanges, but you do need their permission.\n",
    "\n",
    "    You task:\n",
    "    Read the customer's situation and respond to them with the appropriate message and action.\n",
    "    The available actions are: TALK, EXCHANGE, REFUND, or REFUSE.\n",
    "    Select TALK if you do not have enough information to make a final decision. Make sure to ask for the information you need in your MESSAGE!\n",
    "    You must get the customer's permission before processing a REFUND or EXCHANGE.\n",
    "    If you have enough information to make a final decision, provide the customer with a message explaining your decision.\n",
    "    Your response MUST be formatted exactly like the following, with you providing content in the brackets:\n",
    "\n",
    "    ACTION:action\n",
    "    MESSAGE:your message to the customer\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll create a couple of example customer situations to simulate as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_scenarios = {\n",
    "    \"Ankur\": \"Ankur bought a violin but it arrived broken yesterday. He is very frustrated because he has a concert coming up\",\n",
    "    \"Tara\": \"Tara bought a violin 4 months ago and didn't use it as much as she wanted to\",\n",
    "    \"Albert\": \"Albert bought a violin and it arrived in perfect condition, but after a week, he decided he didn't want it anymore. He hasn't used it much\",\n",
    "    \"Hendricks\": \"Hendricks bought a violin and it arrived in perfect condition, but after a week, he decided he didn't want it anymore. He broke a string while playing it\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the customer scenario with our refund policy, we can come up with expected responses for our agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_responses = {\n",
    "    \"Ankur\": \"EXCHAGE\",\n",
    "    \"Tara\": \"REFUSE\",\n",
    "    \"Albert\": \"REFUND\",\n",
    "    \"Hendricks\": \"REFUSE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_customer_prompt(name, persona):\n",
    "    return dedent(\n",
    "        f\"\"\"\n",
    "    You are playing the role of {name}, who is a customer with the following situation:\n",
    "    <situation>{persona}</situation>\n",
    "    You are chatting with a customer support agent. Use the above details to carry out the conversation. \n",
    "    When you feel your issue has been resolved, please include the upper-case word DONE in your response.\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import braintrust\n",
    "import openai\n",
    "\n",
    "braintrust.login(\n",
    "    api_key=os.environ.get(\"BRAINTRUST_API_KEY\", \"Your BRAINTRUST_API_KEY here\")\n",
    ")\n",
    "\n",
    "openai_client = braintrust.wrap_openai(\n",
    "    openai.AsyncOpenAI(\n",
    "        base_url=\"https://braintrustproxy.com/v1\",\n",
    "        default_headers={\"x-bt-use-cache\": \"always\"},\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\", \"Your OPENAI_API_KEY here\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent runaway conversations from chatty AI :)\n",
    "N_CONVERSATION_LIMIT = 10\n",
    "\n",
    "\n",
    "def switch_roles(message):\n",
    "    return {\n",
    "        \"role\": \"user\" if message[\"role\"] == \"assistant\" else \"assistant\",\n",
    "        \"content\": message[\"content\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def reformat_messages_for_final(message, customer_name):\n",
    "    # since we've been reformatting the messages for openai, display \"true\" format to end user\n",
    "    # The last message will always be the agent\n",
    "    return {\n",
    "        \"role\": \"Viola\" if message[\"role\"] == \"user\" else customer_name,\n",
    "        \"content\": message[\"content\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def simulate_conversation(input):\n",
    "    customer_name = input[\"customer_name\"]\n",
    "    customer_scenario = input[\"customer_scenario\"]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": None},  # Will be dynamically filled in\n",
    "        {\"role\": \"user\", \"content\": \"Hi, my name is Viola, how can I help you?\"},\n",
    "    ]\n",
    "    action_taken = False\n",
    "    whose_turn = \"customer\"\n",
    "\n",
    "    while not action_taken and len(messages) < N_CONVERSATION_LIMIT:\n",
    "        if whose_turn == \"customer\":\n",
    "            messages[0][\"content\"] = produce_customer_prompt(\n",
    "                customer_name, customer_scenario\n",
    "            )\n",
    "        else:\n",
    "            messages[0][\"content\"] = CUSTOMER_SUPPORT_AGENT_PROMPT\n",
    "        response = await openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\", messages=messages, max_tokens=150\n",
    "        )\n",
    "        response_message = response.choices[0].message.content\n",
    "\n",
    "        if whose_turn == \"agent\":\n",
    "            action = response_message.split(\"ACTION:\")[1].split(\"\\n\")[0].strip()\n",
    "            response_message = response_message.split(\"MESSAGE:\")[1].strip()\n",
    "            if action != \"TALK\":\n",
    "                action_taken = True\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_message})\n",
    "        whose_turn = \"customer\" if whose_turn == \"agent\" else \"agent\"\n",
    "        # flip user/assistant roles for every message:\n",
    "        if not action_taken:\n",
    "            messages = [messages[0]] + [switch_roles(m) for m in messages[1:]]\n",
    "    # turn message list back into format for end user\n",
    "    messages = [messages[0]] + [\n",
    "        reformat_messages_for_final(m, customer_name) for m in messages\n",
    "    ]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example customer details\n",
    "customer_name = \"John\"\n",
    "customer_scenario = \"John bought a phone from your store 40 days ago and it stopped working. John would like to return it or get a refund.\"\n",
    "\n",
    "# Start the conversation simulation\n",
    "convo = await simulate_conversation(\n",
    "    dict(customer_name=customer_name, customer_scenario=customer_scenario)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braintrust import Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment async hell-4cb0e0cd is running at https://www.braintrust.dev/app/braintrustdata.com/p/Agent%20Evaluation%3A%20Customer%20Support/experiments/async%20hell-4cb0e0cd\n",
      "Agent Evaluation: Customer Support [experiment_name=async hell] (data): 4it [00:00, 11530.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec9c802c2904cfabbc6dd90451ab737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Agent Evaluation: Customer Support [experiment_name=async hell] (tasks):   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "async hell-4cb0e0cd compared to async hell:\n",
      "75.00% (+75.00%) 'score_func' score\t(3 improvements, 0 regressions)\n",
      "\n",
      "0.28s (-29.77%) 'duration'\t(4 improvements, 0 regressions)\n",
      "\n",
      "See results for async hell-4cb0e0cd at https://www.braintrust.dev/app/braintrustdata.com/p/Agent%20Evaluation%3A%20Customer%20Support/experiments/async%20hell-4cb0e0cd\n"
     ]
    }
   ],
   "source": [
    "from autoevals import Score\n",
    "\n",
    "\n",
    "async def score_func(output, expected, metadata, hooks, **kwargs):\n",
    "    return float(output == expected)\n",
    "\n",
    "\n",
    "eval_result = await Eval(\n",
    "    name=\"Agent Evaluation: Customer Support\",\n",
    "    experiment_name=\"async hell\",\n",
    "    data=[\n",
    "        dict(\n",
    "            input=dict(customer_name=name, customer_scenario=scenario),\n",
    "            expected=expected_responses[name],\n",
    "        )\n",
    "        for name, scenario in customer_scenarios.items()\n",
    "    ],\n",
    "    task=simulate_conversation,\n",
    "    scores=[score_func],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
