{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability for Strands Agents on Amazon Bedrock\n",
    "\n",
    "This cookbook guides you through how to deploy a Strands Agent to Amazon Bedrock AgentCore Runtime with built-in observability. The implementation uses Amazon Bedrock Claude models and sends telemetry data to Braintrust through OpenTelemetry.\n",
    "\n",
    "By the end of this cookbook, you'll learn how to:\n",
    "\n",
    "- Build a Strands Agent with web search capabilities using Amazon Bedrock Claude models\n",
    "- Deploy the agent to Amazon Bedrock AgentCore Runtime for managed, scalable hosting\n",
    "- Configure OpenTelemetry to send traces to Braintrust for observability\n",
    "- Invoke the agent through both SDK and boto3 client\n",
    "\n",
    "## Key components\n",
    "\n",
    "- **Strands Agent**: Python framework for building LLM-powered agents with built-in telemetry support\n",
    "- **Amazon Bedrock AgentCore Runtime**: Managed runtime service for hosting and scaling agents on AWS\n",
    "- **OpenTelemetry**: Industry-standard protocol for collecting and exporting telemetry data\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The agent is containerized and deployed to Amazon Bedrock AgentCore Runtime, which provides HTTP endpoints for invocation. Telemetry data flows from the Strands Agent through OTEL exporters to Braintrust for monitoring and debugging. The implementation uses a lazy initialization pattern to ensure proper configuration order.\n",
    "\n",
    "![Architecture diagram](./assets/configure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To get started, make sure you have:\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS credentials configured with Bedrock and AgentCore permissions\n",
    "- A [Braintrust account](https://www.braintrust.dev/signup) and [API key](https://www.braintrust.dev/app/settings?subroute=api-keys)\n",
    "- Docker installed locally\n",
    "- Access to Amazon Bedrock Claude models in us-west-2\n",
    "\n",
    "You'll also want to install required dependencies from the `requirements.txt` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent implementation\n",
    "\n",
    "The agent file (`strands_claude.py`) implements a travel agent with web search capabilities. The implementation uses a lazy initialization pattern to ensure telemetry is configured after environment variables, integrates Amazon Bedrock Claude models through the Strands framework, and includes web search via DuckDuckGo for real-time information. The agent is configured to send traces to Braintrust via OpenTelemetry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile strands_claude.py\n",
    "import os\n",
    "import logging\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.telemetry import StrandsTelemetry\n",
    "from ddgs import DDGS\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR, format=\"[%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(os.getenv(\"AGENT_RUNTIME_LOG_LEVEL\", \"INFO\").upper())\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web for information using DuckDuckGo.\n",
    "\n",
    "    Args:\n",
    "        query: The search query\n",
    "\n",
    "    Returns:\n",
    "        A string containing the search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ddgs = DDGS()\n",
    "        results = ddgs.text(query, max_results=5)\n",
    "\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"{i}. {result.get('title', 'No title')}\\n\"\n",
    "                f\"   {result.get('body', 'No summary')}\\n\"\n",
    "                f\"   Source: {result.get('href', 'No URL')}\\n\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(formatted_results) if formatted_results else \"No results found.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error searching the web: {str(e)}\"\n",
    "\n",
    "# Function to initialize Bedrock model\n",
    "def get_bedrock_model():\n",
    "    region = os.getenv(\"AWS_DEFAULT_REGION\", \"us-west-2\")\n",
    "    model_id = os.getenv(\"BEDROCK_MODEL_ID\", \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n",
    "\n",
    "    bedrock_model = BedrockModel(\n",
    "        model_id=model_id,\n",
    "        region_name=region,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return bedrock_model\n",
    "\n",
    "# Initialize the Bedrock model\n",
    "bedrock_model = get_bedrock_model()\n",
    "\n",
    "# Define the agent's system prompt\n",
    "system_prompt = \"\"\"You are an experienced travel agent specializing in personalized travel recommendations \n",
    "with access to real-time web information. Your role is to find dream destinations matching user preferences \n",
    "using web search for current information. You should provide comprehensive recommendations with current \n",
    "information, brief descriptions, and practical travel details.\"\"\"\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def initialize_agent():\n",
    "    \"\"\"Initialize the agent with proper telemetry configuration.\"\"\"\n",
    "\n",
    "    # Initialize Strands telemetry with 3P configuration\n",
    "    strands_telemetry = StrandsTelemetry()\n",
    "    strands_telemetry.setup_otlp_exporter()\n",
    "    \n",
    "    # Create and cache the agent\n",
    "    agent = Agent(\n",
    "        model=bedrock_model,\n",
    "        system_prompt=system_prompt,\n",
    "        tools=[web_search]\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "@app.entrypoint\n",
    "def strands_agent_bedrock(payload, context=None):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    logger.info(\"[%s] User input: %s\", context.session_id, user_input)\n",
    "    \n",
    "    # Initialize agent with proper configuration\n",
    "    agent = initialize_agent()\n",
    "    \n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AgentCore runtime deployment\n",
    "\n",
    "Next we'll use the starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role, and a requirements file. We'll also configure the starter kit to auto-create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your Dockerfile will be generated based on your application code.\n",
    "\n",
    "<Callout type=\"info\">\n",
    "  When using the `bedrock_agentcore_starter_toolkit` to configure your agent, it configures AgentCore Observability by default. To use Braintrust, you need to disable AgentCore Observability by setting `disable_otel=True`.\n",
    "</Callout>\n",
    "\n",
    "![Configure diagram](./assets/configure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "agent_name = \"strands_braintrust_observability\"\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"strands_claude.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name,\n",
    "    disable_otel=True,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to AgentCore runtime\n",
    "\n",
    "Now that we have a Dockerfile, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime.\n",
    "\n",
    "![Launch diagram](./assets/launch.png)\n",
    "\n",
    "### Configure observability\n",
    "\n",
    "To enable observability, we need to configure the OpenTelemetry endpoint and authentication. The agent will send traces to Braintrust using the OTEL protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Braintrust configuration\n",
    "otel_endpoint = \"https://api.braintrust.dev/otel\"\n",
    "braintrust_api_key = (\n",
    "    \"<braintrust-api-key>\"  # For production, key should be securely stored\n",
    ")\n",
    "braintrust_project_id = \"<braintrust-project-id>\"\n",
    "otel_auth_header = f\"Authorization=Bearer {braintrust_api_key}, x-bt-parent=project_id:{braintrust_project_id}\"\n",
    "\n",
    "\n",
    "launch_result = agentcore_runtime.launch(\n",
    "    env_vars={\n",
    "        \"BEDROCK_MODEL_ID\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Example model ID\n",
    "        \"OTEL_EXPORTER_OTLP_ENDPOINT\": otel_endpoint,\n",
    "        \"OTEL_EXPORTER_OTLP_HEADERS\": otel_auth_header,\n",
    "        \"DISABLE_ADOT_OBSERVABILITY\": \"true\",\n",
    "    }\n",
    ")\n",
    "launch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check deployment status\n",
    "\n",
    "Wait for the runtime to be ready before invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint[\"status\"]\n",
    "end_status = [\"READY\", \"CREATE_FAILED\", \"DELETE_FAILED\", \"UPDATE_FAILED\"]\n",
    "\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint[\"status\"]\n",
    "    print(status)\n",
    "\n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the agent\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload.\n",
    "\n",
    "![Invoke diagram](./assets/invoke.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    {\n",
    "        \"prompt\": \"I'm planning a weekend trip to Orlando. What are the must-visit places and local food I should try?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"\".join(invoke_response[\"response\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging in Braintrust\n",
    "\n",
    "When you invoke the agent, logs are automatically generated for each invocation. Each agent interaction is captured in its own trace, with individual spans for tool calls and model interactions. To view your logs, navigate to your Braintrust project and select the **Logs** tab.\n",
    "\n",
    "The trace view shows the full execution tree, including all agent interactions, tool calls (such as web_search), and model invocations with their latency and token usage.\n",
    "\n",
    "![Trace View](./assets/logs-trace.png)\n",
    "\n",
    "The table view provides a summary of all traces with key metrics like duration, LLM duration, tool calls, and errors.\n",
    "\n",
    "![Table View](./assets/logs-table.png)\n",
    "\n",
    "The traces include detailed information about agent invocation, tool calls, model interactions with latency and token usage, and complete request/response payloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "When you're finished, you can clean up the resources you're not using anymore. This step is optional, but a best practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Delete the AgentCore Runtime and ECR repository\n",
    "agentcore_control_client = boto3.client(\"bedrock-agentcore-control\", region_name=region)\n",
    "\n",
    "ecr_client = boto3.client(\"ecr\", region_name=region)\n",
    "\n",
    "# Delete the runtime\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id,\n",
    ")\n",
    "\n",
    "# Delete the ECR repository\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split(\"/\")[1], force=True\n",
    ")\n",
    "\n",
    "print(\"Cleanup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now that you have a working Strands Agent deployed to Amazon Bedrock AgentCore Runtime with full observability, you can build on this foundation:\n",
    "\n",
    "- Add more [tools](/docs/core/functions/tools) to expand agent capabilities beyond web search\n",
    "- Create [custom scorers](/docs/core/functions/scorers) to evaluate agent performance and accuracy\n",
    "- Build [evaluation datasets](/docs/core/datasets) from production logs to continuously improve your agent\n",
    "- Use the [playground](/docs/core/playground) to test and refine agent behavior before deploying updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
