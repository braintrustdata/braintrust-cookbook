{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating and iterating on AI apps with Lovable\n",
        "\n",
        "[Lovable](https://lovable.dev/) is a no-code platform that helps non-technical builders create real applications with AI features. After building your app with Lovable, the next step is connecting it to Braintrust so you can see what the AI is doing and iterate confidently. This cookbook guides you through adding Braintrust observability and evaluations to your Lovable app, which runs on Supabase Edge Functions with Deno.\n",
        "\n",
        "By the end of this cookbook, you'll learn how to:\n",
        "\n",
        "- Add Braintrust logging to a Lovable app running on Supabase Edge + Deno\n",
        "- Configure the Braintrust SDK to send traces for observability\n",
        "- Run evals to inspect AI behavior including prompts, tool calls, and responses\n",
        "- Set up remote evals to test changes in your Lovable AI features before deploying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting started\n",
        "\n",
        "To get started, make sure you have:\n",
        "\n",
        "- A Lovable account with an existing app\n",
        "- A [Braintrust account](https://www.braintrust.dev/signup) and [API key](https://www.braintrust.dev/app/settings?subroute=api-keys)\n",
        "- Access to your Lovable app's Edge Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add your API key to Lovable\n",
        "\n",
        "From your Lovable chat interface:\n",
        "\n",
        "1. Select the cloud icon to access secrets management\n",
        "2. Add a new secret named `BRAINTRUST_API_KEY`\n",
        "3. Paste your Braintrust API key as the value\n",
        "4. Save the secret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Secrets UI screenshot 2](./assets/secrets-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure logging in your Edge Function\n",
        "\n",
        "Ask Lovable to configure Braintrust logging by pasting this prompt into the Lovable chat:\n",
        "\n",
        "```\n",
        "Add Braintrust logging to [project name]'s Edge Function following this pattern:\n",
        "\n",
        "1. Import the Braintrust SDK at the top of the Edge Function file.\n",
        "2. Initialize the logger in the request handler using env var BRAINTRUST_API_KEY, with projectName set to your Braintrust project. Use asyncFlush: false to send logs immediately.\n",
        "3. Create a root span named `request` and child spans for each major step (e.g., `ai_call`, `processing`).\n",
        "   - Wrap main logic with `braintrust.traced(..., { name: \"request\" })`.\n",
        "   - Create child spans with `rootSpan.startSpan(\"step_name\")` and always `await span.end()` in `finally`.\n",
        "   - Log input and output at each span for detailed tracing.\n",
        "   - Provide a safe fallback path if the logger is unavailable.\n",
        "4. Log inputs with clear fields (e.g., userPrompt, systemPrompt in metadata, not nested in messages).\n",
        "5. Log outputs with both preview and full response.\n",
        "6. If you later handle images, log full base64 data URLs: `data:image/[type];base64,[data]`.\n",
        "7. Handle all errors and end spans in finally blocks.\n",
        "8. Use or adapt this template: \n",
        "import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\n",
        "\n",
        "// Import Braintrust SDK\n",
        "let braintrust: any = null;\n",
        "try {\n",
        "  braintrust = await import(\"https://esm.sh/braintrust@0.4.8\");\n",
        "} catch (e) {\n",
        "  // Braintrust not available, continue without logging\n",
        "}\n",
        "\n",
        "const corsHeaders = {\n",
        "  \"Access-Control-Allow-Origin\": \"*\",\n",
        "  \"Access-Control-Allow-Headers\": \"authorization, x-client-info, apikey, content-type\",\n",
        "};\n",
        "\n",
        "serve(async (req) => {\n",
        "  if (req.method === \"OPTIONS\") {\n",
        "    return new Response(null, { headers: corsHeaders });\n",
        "  }\n",
        "\n",
        "  try {\n",
        "    // Initialize logger\n",
        "    const BRAINTRUST_API_KEY = Deno.env.get(\"BRAINTRUST_API_KEY\");\n",
        "    const logger = braintrust && BRAINTRUST_API_KEY\n",
        "      ? braintrust.initLogger({\n",
        "        projectName: \"YOUR_PROJECT_NAME\", // Replace with your project name\n",
        "        apiKey: BRAINTRUST_API_KEY,\n",
        "        asyncFlush: false,\n",
        "      })\n",
        "      : null;\n",
        "\n",
        "    // Process request with or without Braintrust\n",
        "    if (logger) {\n",
        "      return await braintrust.traced(async (rootSpan: any) => {\n",
        "        try {\n",
        "          const body = await req.json();\n",
        "\n",
        "          // Log input at root span\n",
        "          await rootSpan?.log({ input: body });\n",
        "\n",
        "          // ============================================\n",
        "          // CHILD SPAN EXAMPLE\n",
        "          // ============================================\n",
        "          const childSpan = rootSpan.startSpan(\"example_step\");\n",
        "          let stepResult;\n",
        "          try {\n",
        "            // ← Add your logic here\n",
        "            // Example: stepResult = await yourFunction(body);\n",
        "            stepResult = body; // Placeholder - replace with your actual logic\n",
        "\n",
        "            await childSpan?.log({\n",
        "              input: body,\n",
        "              output: stepResult\n",
        "            });\n",
        "          } finally {\n",
        "            await childSpan?.end();\n",
        "          }\n",
        "\n",
        "          // Add more child spans as needed...\n",
        "\n",
        "          // Log output at root span\n",
        "          const finalResult = stepResult; // ← Replace with your actual result\n",
        "          await rootSpan?.log({ output: finalResult });\n",
        "          await rootSpan?.end();\n",
        "\n",
        "          return new Response(JSON.stringify(finalResult), {\n",
        "            headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n",
        "          });\n",
        "        } catch (error: any) {\n",
        "          await rootSpan?.log({ error: error?.message });\n",
        "          await rootSpan?.end();\n",
        "          throw error;\n",
        "        }\n",
        "      }, { name: \"request\" });\n",
        "    } else {\n",
        "      // Fallback without Braintrust\n",
        "      const body = await req.json();\n",
        "      // ← Add your logic here (same as above, just without spans)\n",
        "      // Example: const result = await yourFunction(body);\n",
        "      const result = body; // Placeholder - replace with your actual logic\n",
        "      return new Response(JSON.stringify(result), {\n",
        "        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n",
        "      });\n",
        "    }\n",
        "  } catch (error: any) {\n",
        "    return new Response(JSON.stringify({ error: error?.message }), {\n",
        "      status: 500,\n",
        "      headers: corsHeaders,\n",
        "    });\n",
        "  }\n",
        "});\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View logs\n",
        "\n",
        "After implementing the logging, run your AI feature end-to-end. Start with text-only if you prefer, and you can add image flows later. \n",
        "\n",
        "![Run flow](./assets/verify-logs-1.png)\n",
        "\n",
        "Navigate to your Braintrust project and select the **Logs** tab to view traces. Confirm that the traces are streaming in real time. The `ai_gateway_call` child span will show system and user prompts. \n",
        "\n",
        "![Logs tab](./assets/verify-logs-2.png)\n",
        "\n",
        "Each trace will include detailed information about:\n",
        "- Request inputs and outputs\n",
        "- AI model interactions with prompts\n",
        "- Processing steps with latency\n",
        "- Complete request/response payloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running eval experiments\n",
        "\n",
        "Once logging is live, you can run evals to compare prompt or agent changes and score results:\n",
        "\n",
        "1. Create a playground directly from Logs\n",
        "2. Ask Braintrust's AI assistant to add custom scorers\n",
        "3. Experiment with different models and prompts\n",
        "4. Compare results side-by-side"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running remote evals\n",
        "\n",
        "You can use remote evals to tweak prompts or tool calls locally, then test your cloud function as if it were deployed.\n",
        "\n",
        "1. Ask Lovable for the exact Supabase Edge Function URL and substitute it below\n",
        "2. Run a local dev server\n",
        "3. Expose it via Cloudflare Tunnel\n",
        "4. Register the tunnel URL in Braintrust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { Eval } from \"braintrust\";\n",
        "import { z } from \"zod\";\n",
        "\n",
        "export default Eval(\"My Function Remote Eval\", {\n",
        "  task: async (input, { parameters }) => {\n",
        "    const functionUrl = parameters?.functionUrl || input?.functionUrl;\n",
        "    const systemPrompt =\n",
        "      parameters?.systemPrompt || input?.systemPrompt || \"You are a helpful assistant.\";\n",
        "    const userPrompt = parameters?.userPrompt || input?.userPrompt;\n",
        "\n",
        "    if (!functionUrl) throw new Error(\"Missing functionUrl\");\n",
        "\n",
        "    const resp = await fetch(functionUrl, {\n",
        "      method: \"POST\",\n",
        "      headers: { \"Content-Type\": \"application/json\" },\n",
        "      body: JSON.stringify(input || {}),\n",
        "    });\n",
        "\n",
        "    if (!resp.ok) throw new Error(`Function error ${resp.status}: ${await resp.text()}`);\n",
        "\n",
        "    return await resp.json();\n",
        "  },\n",
        "\n",
        "  scores: [],\n",
        "\n",
        "  parameters: {\n",
        "    functionUrl: z.string().describe(\"Supabase Edge Function URL\").default(\"https://your-project.supabase.co/functions/v1/your-function\"),\n",
        "  },\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run the remote eval, start the dev server and tunnel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "npx braintrust eval my - function- eval.js--dev--dev - host 0.0.0.0 --dev - port 8400\n",
        "npx cloudflared tunnel--url http://localhost:8400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, register the tunnel URL. You can do this from a playground or your project configuration.\n",
        "\n",
        "Add the tunnel URL (for example, `https://xyz-abc-123.trycloudflare.com`):\n",
        "\n",
        "![Remote eval screenshot 2](./assets/remote-eval-2.png)\n",
        "\n",
        "And run your remote eval:\n",
        "\n",
        "![Remote eval screenshot 2](./assets/remote-eval-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each time you'd like to run a remote eval, make sure you have the dev server running, Cloudflare Tunnel active, and Braintrust configured with the current tunnel URL. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "You can ask Lovable to help you troubleshoot in the chat window. \n",
        "\n",
        "### Traces not showing up\n",
        "\n",
        "- Verify secret name in Supabase matches your code\n",
        "- Ensure Braintrust `projectName` is exact\n",
        "- Look for \"[Braintrust]\" console messages\n",
        "- Ensure every span calls `await span.end()`\n",
        "\n",
        "### Images not displaying\n",
        "\n",
        "- Log full base64 data URLs\n",
        "- Keep payloads under ~10 MB per trace\n",
        "- Use format: `data:image/png;base64,...`\n",
        "- Don't log booleans — include the actual data\n",
        "\n",
        "### Errors in logs\n",
        "\n",
        "- Verify SDK import succeeded\n",
        "- Check that API key is valid\n",
        "- Ensure `asyncFlush: false` is set\n",
        "- Confirm outbound network access is allowed from Supabase Edge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "Now that you have a Lovable app with full observability and evaluation capabilities, you can:\n",
        "\n",
        "- Create [custom scorers](/docs/evaluate/write-scorers) to evaluate AI quality against specific criteria\n",
        "- Build [evaluation datasets](/docs/annotate/datasets) from production logs to continuously improve your app\n",
        "- Use the [playground](/docs/evaluate/playgrounds) to experiment with prompts before deploying changes\n",
        "- Add more AI features to your Lovable app with confidence in their quality"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "typescript",
        "version": 5
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "nbconvert_exporter": "typescript",
      "pygments_lexer": "typescript",
      "version": "5.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
