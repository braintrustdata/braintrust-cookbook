{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f4c12a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c34ffc-a3a1-4915-b866-e32d97a98e7c",
   "metadata": {},
   "source": [
    "# Tool calls in LLaMa 3.1\n",
    "\n",
    "LLaMa 3.1 is distributed as an instruction-tuned model with 8B, 70B, and 405B parameter variants. As part of the release, Meta mentioned that\n",
    "\n",
    "> These are multilingual and have a significantly longer context length of 128K, state-of-the-art tool use, and overall stronger reasoning capabilities.\n",
    "\n",
    "Let's dig into how we can use these models with tools, and run an eval to see how they compare to gpt-4o on a benchmark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78277a53-7763-41cc-aa51-89354e729875",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You can access LLaMa 3.1 models through inference services like [Together](https://www.together.ai/), which has generous rate limits and OpenAI protocol compatibility. We'll use Together, through the\n",
    "[Braintrust proxy](https://www.braintrust.dev/docs/guides/proxy) to access LLaMa 3.1 and OpenAI models.\n",
    "\n",
    "To get started, make sure you have a Braintrust account and an API key for [Together](https://www.together.ai) and [OpenAI](https://platform.openai.com/). Make sure to plug them into your Braintrust account's\n",
    "[AI secrets](https://www.braintrust.dev/app/settings?subroute=secrets) configuration and acquire a [BRAINTRUST_API_KEY](https://www.braintrust.dev/app/settings?subroute=api-keys). Feel free to put your BRAINTRUST_API_KEY in a `.env.local` file next to this notebook, or just hardcode it into the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e621c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv from \"dotenv\";\n",
    "import * as fs from \"fs\";\n",
    "\n",
    "if (fs.existsSync(\".env.local\")) {\n",
    "  dotenv.config({ path: \".env.local\", override: true });\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef910f35-4b64-403b-b5fb-7c3a9ebde8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(node:36351) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\n",
      "(Use `node --trace-deprecation ...` to show where the warning was created)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, I'm a large language model, I don't have real-time access to current weather conditions. But I can suggest some ways for you to find out the current weather in Tokyo:\n",
      "\n",
      "1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the Japan Meteorological Agency (JMA) website to get the current weather conditions in Tokyo.\n",
      "2. **Use a weather app**: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get the current weather conditions in Tokyo.\n",
      "3. **Check social media**: You can also check social media platforms like Twitter or Facebook to see if there are any updates on the weather in Tokyo.\n",
      "\n",
      "That being said, I can provide you with some general information about the climate in Tokyo. Tokyo has a humid subtropical climate, with four distinct seasons:\n",
      "\n",
      "* **Spring (March to May)**: Mild temperatures, with average highs around 18°C (64°F) and lows around 10°C (50°F).\n",
      "* **Summer (June to August)**: Hot and humid, with average highs around 28°C (82°F) and lows around 22°C (72°F).\n",
      "* **Autumn (September to November)**: Comfortable temperatures, with average highs around 20°C (68°F) and lows around 12°C (54°F).\n",
      "* **Winter (December to February)**: Cool to cold, with average highs around 10°C (50°F) and lows around 2°C (36°F).\n",
      "\n",
      "Please note that these are general temperature ranges, and the actual weather conditions in Tokyo can vary from year to year.\n"
     ]
    }
   ],
   "source": [
    "import { OpenAI } from \"openai\";\n",
    "import { wrapOpenAI } from \"braintrust\";\n",
    "\n",
    "const client = wrapOpenAI(\n",
    "  new OpenAI({\n",
    "    apiKey: process.env.BRAINTRUST_API_KEY,\n",
    "    baseURL: \"https://api.braintrust.dev/v1/proxy\",\n",
    "    defaultHeaders: { \"x-bt-use-cache\": \"never\" },\n",
    "  })\n",
    ");\n",
    "\n",
    "const LLAMA31_8B = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\";\n",
    "const LLAMA31_70B = \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\";\n",
    "const LLAMA31_405B = \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\";\n",
    "\n",
    "const response = await client.chat.completions.create({\n",
    "  model: LLAMA31_8B,\n",
    "  messages: [\n",
    "    {\n",
    "      role: \"user\",\n",
    "      content: \"What is the weather in Tokyo?\",\n",
    "    },\n",
    "  ],\n",
    "  max_tokens: 1024,\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "console.log(response.choices[0].message.content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28709b66",
   "metadata": {},
   "source": [
    "As expected, the model can't answer the question without access to some tools. Traditionally, LLaMa models haven't supported tool calling. Some inference providers have attempted to solve this with controlled generation or similar methods, although to limited success. However, the [llama-agentic-system](https://github.com/meta-llama/llama-agentic-system/blob/main/llama_agentic_system/system_prompt.py#L71) codebase alludes to a new approach to tool calls:\n",
    "\n",
    "```text\n",
    "Think very carefully before calling functions.\n",
    "If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n",
    "\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
    "```\n",
    "\n",
    "Let's see if we can make this work with the commonly used weather tool definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305ef967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function=get_current_weather>{\"location\": \"Tokyo, JP\"}</function>\n"
     ]
    }
   ],
   "source": [
    "const weatherTool = {\n",
    "  name: \"get_current_weather\",\n",
    "  description: \"Get the current weather in a given location\",\n",
    "  parameters: {\n",
    "    type: \"object\",\n",
    "    properties: {\n",
    "      location: {\n",
    "        type: \"string\",\n",
    "        description: \"The city and state, e.g. San Francisco, CA\",\n",
    "      },\n",
    "    },\n",
    "    required: [\"location\"],\n",
    "  },\n",
    "};\n",
    "\n",
    "const toolPrompt = `You have access to the following functions:\n",
    "\n",
    "Use the function '${weatherTool.name}' to '${weatherTool.description}':\n",
    "${JSON.stringify(weatherTool)}\n",
    "\n",
    "If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n",
    "\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
    "\n",
    "Reminder:\n",
    "- If looking for real time information use relevant functions before falling back to brave_search\n",
    "- Function calls MUST follow the specified format, start with <function= and end with </function>\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "\n",
    "`;\n",
    "\n",
    "const response = await client.chat.completions.create({\n",
    "  model: LLAMA31_8B,\n",
    "  messages: [\n",
    "    {\n",
    "      role: \"system\",\n",
    "      content: toolPrompt,\n",
    "    },\n",
    "    {\n",
    "      role: \"user\",\n",
    "      content: \"What is the weather in Tokyo?\",\n",
    "    },\n",
    "  ],\n",
    "  max_tokens: 1024,\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "console.log(response.choices[0].message.content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3f503",
   "metadata": {},
   "source": [
    "Wow cool! Looks like we can get the model to call the tool. Let's quickly write a parser that can extract the function call from the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbb28746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  `<function=select_choice>{\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it. The submitted answer contains additional information that is not present in the expert answer, but the core information is the same. For example, the submitted answer 'The weather in Tokyo is extremely hot' is a superset of the expert answer 'The weather in Tokyo is hot' because it contains additional information about the temperature being extremely high. However, the submitted answer is fully consistent with the expert answer in terms of the core information, which is that the weather in Tokyo is hot. Therefore, the correct answer is (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\",\"choice\":\"B\"}`,\n",
      "  'select_choice',\n",
      "  `{\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it. The submitted answer contains additional information that is not present in the expert answer, but the core information is the same. For example, the submitted answer 'The weather in Tokyo is extremely hot' is a superset of the expert answer 'The weather in Tokyo is hot' because it contains additional information about the temperature being extremely high. However, the submitted answer is fully consistent with the expert answer in terms of the core information, which is that the weather in Tokyo is hot. Therefore, the correct answer is (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\",\"choice\":\"B\"}`,\n",
      "  index: 0,\n",
      "  input: `<function=select_choice>{\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it. The submitted answer contains additional information that is not present in the expert answer, but the core information is the same. For example, the submitted answer 'The weather in Tokyo is extremely hot' is a superset of the expert answer 'The weather in Tokyo is hot' because it contains additional information about the temperature being extremely high. However, the submitted answer is fully consistent with the expert answer in terms of the core information, which is that the weather in Tokyo is hot. Therefore, the correct answer is (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\",\"choice\":\"B\"}`,\n",
      "  groups: undefined\n",
      "]\n",
      "{\n",
      "  functionName: 'select_choice',\n",
      "  args: {\n",
      "    reasons: \"The submitted answer is a superset of the expert answer and is fully consistent with it. The submitted answer contains additional information that is not present in the expert answer, but the core information is the same. For example, the submitted answer 'The weather in Tokyo is extremely hot' is a superset of the expert answer 'The weather in Tokyo is hot' because it contains additional information about the temperature being extremely high. However, the submitted answer is fully consistent with the expert answer in terms of the core information, which is that the weather in Tokyo is hot. Therefore, the correct answer is (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\",\n",
      "    choice: 'B'\n",
      "  }\n",
      "}\n",
      "[\n",
      "  '<function=select_choice>{\"choice\":\"E\",\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it.\"}</function>',\n",
      "  'select_choice',\n",
      "  '{\"choice\":\"E\",\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it.\"}',\n",
      "  index: 0,\n",
      "  input: '<function=select_choice>{\"choice\":\"E\",\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it.\"}</function>',\n",
      "  groups: undefined\n",
      "]\n",
      "{\n",
      "  functionName: 'select_choice',\n",
      "  args: {\n",
      "    choice: 'E',\n",
      "    reasons: 'The submitted answer is a superset of the expert answer and is fully consistent with it.'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "function parseToolResponse(response: string) {\n",
    "  const functionRegex = /<function=(\\w+)>(.*?)(?:<\\/function>|$)/;\n",
    "  const match = response.match(functionRegex);\n",
    "\n",
    "  if (match) {\n",
    "    const [, functionName, argsString] = match;\n",
    "    try {\n",
    "      const args = JSON.parse(argsString);\n",
    "      return {\n",
    "        functionName,\n",
    "        args,\n",
    "      };\n",
    "    } catch (error) {\n",
    "      console.error(\"Error parsing function arguments:\", error);\n",
    "      return null;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return null;\n",
    "}\n",
    "\n",
    "// const parsedResponse = parseToolResponse(response.choices[0].message.content);\n",
    "// console.log(parsedResponse);\n",
    "\n",
    "console.log(\n",
    "  parseToolResponse(\n",
    "    `<function=select_choice>{\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it. The submitted answer contains additional information that is not present in the expert answer, but the core information is the same. For example, the submitted answer 'The weather in Tokyo is extremely hot' is a superset of the expert answer 'The weather in Tokyo is hot' because it contains additional information about the temperature being extremely high. However, the submitted answer is fully consistent with the expert answer in terms of the core information, which is that the weather in Tokyo is hot. Therefore, the correct answer is (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\",\"choice\":\"B\"}`\n",
    "  )\n",
    ");\n",
    "console.log(\n",
    "  parseToolResponse(\n",
    "    `<function=select_choice>{\"choice\":\"E\",\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it.\"}</function>`\n",
    "  )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae5ffe-c66d-4bbd-8b99-08a09af5900d",
   "metadata": {},
   "source": [
    "## A real use case: LLM-as-a-Judge evaluators that make tool calls\n",
    "\n",
    "At Braintrust, we maintain a suite of evaluator functions in the [Autoevals](https://github.com/braintrustdata/autoevals) library. Many of these evaluators, like `Factuality`, are \"LLM-as-a-Judge\"\n",
    "evaluators that use a well-crafted prompt to an LLM to reason about the quality of a response. We are big fans of tool calling, and leverage it extensively in `autoevals` to make it easy and reliable\n",
    "to parse the scores and reasoning they produce.\n",
    "\n",
    "As we change autoevals, we run evals to make sure we improve performance and avoid regressing key scenarios. We'll run some of our autoeval evals as a way of assessing how well LLaMa 3.1 stacks up to gpt-4o.\n",
    "\n",
    "Here is a quick example of the `Factuality` scorer, a popular LLM-as-a-Judge evaluator that uses the following prompt:\n",
    "\n",
    "```ansi\n",
    "You are comparing a submitted answer to an expert answer on a given question. Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Question]: {{{input}}}\n",
    "************\n",
    "[Expert]: {{{expected}}}\n",
    "************\n",
    "[Submission]: {{{output}}}\n",
    "************\n",
    "[END DATA]\n",
    "\n",
    "Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\n",
    "The submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:\n",
    "(A) The submitted answer is a subset of the expert answer and is fully consistent with it.\n",
    "(B) The submitted answer is a superset of the expert answer and is fully consistent with it.\n",
    "(C) The submitted answer contains all the same details as the expert answer.\n",
    "(D) There is a disagreement between the submitted answer and the expert answer.\n",
    "(E) The answers differ, but these differences don't matter from the perspective of factuality.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eeb7c5f-f502-4f7e-b958-981dea2b62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  name: 'Factuality',\n",
      "  score: 1,\n",
      "  metadata: {\n",
      "    rationale: '1. The expert answer states that the weather in Tokyo is \"extremely hot.\"\\n' +\n",
      "      '2. The submitted answer states that the weather in Tokyo is \"scorching.\"\\n' +\n",
      "      '3. Both \"extremely hot\" and \"scorching\" convey the same factual content, indicating very high temperatures.\\n' +\n",
      "      '4. There is no additional information in either answer that would make one a subset or superset of the other.\\n' +\n",
      "      '5. Therefore, the submitted answer contains all the same details as the expert answer.',\n",
      "    choice: 'C'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { Factuality } from \"autoevals\";\n",
    "\n",
    "console.log(\n",
    "  await Factuality({\n",
    "    input: \"What is the weather in Tokyo?\",\n",
    "    output: \"The weather in Tokyo is scorching.\",\n",
    "    expected: \"The weather in Tokyo is extremely hot.\",\n",
    "  })\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5166207",
   "metadata": {},
   "source": [
    "Now let's reproduce this with LLaMa 3.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93a5585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  name: 'Factuality',\n",
      "  score: 0.6,\n",
      "  metadata: {\n",
      "    rationale: \"The submitted answer 'The weather in Tokyo is scorching' is a superset of the expert answer 'The weather in Tokyo is extremely hot' because it includes the same information and adds more detail. The word 'scorching' is a synonym for 'extremely hot', so the submitted answer is fully consistent with the expert answer.\",\n",
      "    choice: 'B'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { templates } from \"autoevals\";\n",
    "import * as yaml from \"js-yaml\";\n",
    "import mustache from \"mustache\";\n",
    "\n",
    "const template = yaml.load(templates[\"factuality\"]);\n",
    "\n",
    "const selectTool = {\n",
    "  name: \"select_choice\",\n",
    "  description: \"Call this function to select a choice.\",\n",
    "  parameters: {\n",
    "    properties: {\n",
    "      reasons: {\n",
    "        description:\n",
    "          \"Write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.\",\n",
    "        title: \"Reasoning\",\n",
    "        type: \"string\",\n",
    "      },\n",
    "      choice: {\n",
    "        description: \"The choice\",\n",
    "        title: \"Choice\",\n",
    "        type: \"string\",\n",
    "        enum: Object.keys(template.choice_scores),\n",
    "      },\n",
    "    },\n",
    "    required: [\"reasons\", \"choice\"],\n",
    "    title: \"CoTResponse\",\n",
    "    type: \"object\",\n",
    "  },\n",
    "};\n",
    "\n",
    "async function LLaMaFactuality({\n",
    "  model,\n",
    "  input,\n",
    "  output,\n",
    "  expected,\n",
    "}: {\n",
    "  model: string;\n",
    "  input: string;\n",
    "  output: string;\n",
    "  expected: string;\n",
    "}) {\n",
    "  const toolPrompt = `You have access to the following functions:\n",
    "\n",
    "Use the function '${selectTool.name}' to '${selectTool.description}':\n",
    "${JSON.stringify(selectTool)}\n",
    "\n",
    "If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n",
    "\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
    "\n",
    "Reminder:\n",
    "- If looking for real time information use relevant functions before falling back to brave_search\n",
    "- Function calls MUST follow the specified format, start with <function= and end with </function>\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "`;\n",
    "\n",
    "  const response = await client.chat.completions.create({\n",
    "    model,\n",
    "    messages: [\n",
    "      {\n",
    "        role: \"system\",\n",
    "        content: toolPrompt,\n",
    "      },\n",
    "      {\n",
    "        role: \"user\",\n",
    "        content: mustache.render(template.prompt, {\n",
    "          input,\n",
    "          output,\n",
    "          expected,\n",
    "        }),\n",
    "      },\n",
    "    ],\n",
    "    temperature: 0,\n",
    "    max_tokens: 2048,\n",
    "  });\n",
    "\n",
    "  try {\n",
    "    const parsed = parseToolResponse(response.choices[0].message.content);\n",
    "    return {\n",
    "      name: \"Factuality\",\n",
    "      score: template.choice_scores[parsed?.args.choice],\n",
    "      metadata: {\n",
    "        rationale: parsed?.args.reasons,\n",
    "        choice: parsed?.args.choice,\n",
    "      },\n",
    "    };\n",
    "  } catch (e) {\n",
    "    return {\n",
    "      name: \"Factuality\",\n",
    "      score: null,\n",
    "      metadata: {\n",
    "        error: `${e}`,\n",
    "      },\n",
    "    };\n",
    "  }\n",
    "}\n",
    "\n",
    "console.log(\n",
    "  await LLaMaFactuality({\n",
    "    model: LLAMA31_8B,\n",
    "    input: \"What is the weather in Tokyo?\",\n",
    "    output: \"The weather in Tokyo is scorching.\",\n",
    "    expected: \"The weather in Tokyo is extremely hot.\",\n",
    "  })\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7efe1",
   "metadata": {},
   "source": [
    "Ok interesting! It parses but the response is a little different from the GPT-4o response. Let's put this to the test at scale with some evals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c179efc",
   "metadata": {},
   "source": [
    "## Running evals\n",
    "\n",
    "We use a subset of the [CoQA](https://stanfordnlp.github.io/coqa/) dataset to test the Factuality scorer. Let's load the dataset and take a look at an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5bdca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factuality\n",
      "{\n",
      "  name: 'Factuality',\n",
      "  score: 0,\n",
      "  metadata: {\n",
      "    rationale: '1. The question asks about the color of Cotton.\\n' +\n",
      "      \"2. The expert answer is 'white,' which directly addresses the color of Cotton.\\n\" +\n",
      "      \"3. The submitted answer is 'in a barn,' which does not address the color of Cotton at all.\\n\" +\n",
      "      '4. Since the submitted answer does not provide any information about the color of Cotton, it conflicts with the expert answer.\\n' +\n",
      "      '\\n' +\n",
      "      'Therefore, there is a disagreement between the submitted answer and the expert answer.',\n",
      "    choice: 'D'\n",
      "  }\n",
      "}\n",
      "LLaMa-3.1-8B Factuality\n",
      "{\n",
      "  name: 'Factuality',\n",
      "  score: 0,\n",
      "  metadata: {\n",
      "    rationale: \"The submitted answer 'in a barn' does not contain any information about the color of Cotton, which is the topic of the question. The expert answer 'white' is a specific fact about Cotton. Therefore, the submitted answer is not a subset or superset of the expert answer, and it does not contain all the same details as the expert answer. There is a disagreement between the submitted answer and the expert answer.\",\n",
      "    choice: 'D'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "interface CoqaCase {\n",
    "  input: {\n",
    "    input: string;\n",
    "    output: string;\n",
    "    expected: string;\n",
    "  };\n",
    "  expected: number;\n",
    "}\n",
    "\n",
    "const data: CoqaCase[] = JSON.parse(\n",
    "  fs.readFileSync(\"coqa-factuality.json\", \"utf-8\")\n",
    ");\n",
    "\n",
    "console.log(\"Factuality\");\n",
    "console.log(await Factuality(data[1].input));\n",
    "\n",
    "console.log(\"LLaMa-3.1-8B Factuality\");\n",
    "console.log(\n",
    "  await LLaMaFactuality({\n",
    "    model: LLAMA31_8B,\n",
    "    ...data[1].input,\n",
    "  })\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964befc0",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "### GPT-4o\n",
    "\n",
    "Let's run a full eval with gpt-4o, LLaMa-3.1-8B, LLaMa-3.1-70B, and LLaMa-3.1-405B to see how they stack up. Since the evaluator generates a number\n",
    "between 0 and 1, we'll use the `NumericDiff` scorer to assess accuracy, and a custom `NonNull` scorer to measure how many invalid tool calls are generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ea3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://www.braintrust.dev/api/experiment/register\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://www.braintrust.dev/api/base_experiment/get_id\n",
      "RUNNING GET WITH URL https://d3p9hsahjc1cvu.cloudfront.net/experiment-comparison2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ████████████████████████░░░░░░░░░░░░░░░░ | LLaMa-3.1-Tools [experimentName=gpt-4o]  |  60% | 60/100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "gpt-4o-81ec7a1c compared to gpt-4o-310fd3e3:\n",
      "84.58% (-1.67%) 'NumericDiff' score\t(0 improvements, 1 regressions)\n",
      "100.00% (0.00%) 'NonNull'     score\t(0 improvements, 0 regressions)\n",
      "\n",
      "4.28s 'duration'      \t(13 improvements, 47 regressions)\n",
      "0.00$ 'estimated_cost'\t(20 improvements, 15 regressions)\n",
      "\n",
      "See results for gpt-4o-81ec7a1c at https://www.braintrust.dev/app/braintrustdata.com/p/LLaMa-3.1-Tools/experiments/gpt-4o-81ec7a1c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import { Eval } from \"braintrust\";\n",
    "import { NumericDiff } from \"autoevals\";\n",
    "\n",
    "function NonNull({ output }: { output: number | null }) {\n",
    "  return output !== null && output !== undefined ? 1 : 0;\n",
    "}\n",
    "\n",
    "const evalResult = await Eval(\"LLaMa-3.1-Tools\", {\n",
    "  data: data,\n",
    "  task: async (input) =>\n",
    "    (\n",
    "      await Factuality({\n",
    "        ...input,\n",
    "        openAiDefaultHeaders: { \"x-bt-use-cache\": \"never\" },\n",
    "      })\n",
    "    ).score,\n",
    "  scores: [NumericDiff, NonNull],\n",
    "  experimentName: \"gpt-4o\",\n",
    "  metadata: {\n",
    "    model: \"gpt-4o\",\n",
    "  },\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629a3a4",
   "metadata": {},
   "source": [
    "It looks like GPT-4o does pretty well. Tool calling has been a highlight of OpenAI's feature set for a while, so it's not surprising that it's able to successfully parse 100% of the tool calls.\n",
    "\n",
    "![gpt-4o-result](./assets/gpt-4o-result.png)\n",
    "\n",
    "### LLama-3.1-8B, 70B, and 405B\n",
    "\n",
    "Now let's evaluate each of the LLaMa-3.1 models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "449cd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://www.braintrust.dev/api/experiment/register\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Bad escaped character in JSON at position 61 (line 1 column 62)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://www.braintrust.dev/api/base_experiment/get_id\n",
      "RUNNING GET WITH URL https://d3p9hsahjc1cvu.cloudfront.net/experiment-comparison2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ████████████████████████░░░░░░░░░░░░░░░░ | LLaMa-3.1-Tools [experimentName=meta-... |  60% | 60/100 datapoints\n",
      "Evaluator LLaMa-3.1-Tools [experimentName=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo] failed with 2 errors. This evaluation (\"LLaMa-3.1-Tools [experimentName=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo]\") will not be fully logged.\n",
      "InternalServerError: 520 <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.together.xyz | 520: Web server is returning an unknown error</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Web server is returning an unknown error</span>\n",
      "              <span class=\"code-label\">Error code 520</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2024-07-26 23:45:30 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">San Jose</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.together.xyz</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>There is an unknown connection issue between Cloudflare and the origin web server. As a result, the web page can not be displayed.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                          <h3 class=\"text-15 font-semibold mb-2\">If you are a visitor of this website:</h3>\n",
      "      <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "\n",
      "      <h3 class=\"text-15 font-semibold mb-2\">If you are the owner of this website:</h3>\n",
      "      <p><span>There is an issue between Cloudflare's cache and your origin web server. Cloudflare monitors for these errors and automatically investigates the cause. To help support the investigation, you can pull the corresponding error log from your web server and submit it our support team.  Please include the Ray ID (which is at the bottom of this error page).</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171936-Error-520\">Additional troubleshooting resources</a>.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">8a9843869262f9fd</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">2a06:98c0:3600::103</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "    at APIError.generate (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/error.js:66:20)\n",
      "    at OpenAI.makeStatusError (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/core.js:275:33)\n",
      "    at OpenAI.makeRequest (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/core.js:318:30)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5) {\n",
      "  status: 520,\n",
      "  headers: {\n",
      "    'cf-ray': '8a98437fa913f9fd-SJC',\n",
      "    connection: 'keep-alive',\n",
      "    'content-type': 'text/html; charset=UTF-8',\n",
      "    date: 'Fri, 26 Jul 2024 23:45:30 GMT',\n",
      "    nel: '{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}',\n",
      "    'referrer-policy': 'same-origin',\n",
      "    'report-to': '{\"endpoints\":[{\"url\":\"https:\\\\/\\\\/a.nel.cloudflare.com\\\\/report\\\\/v4?s=Ira0zHRws6aKryqjzMP%2FPo3p9GlIoIqH2fGOC6A%2B2uGBsft980%2BWNAeQp3F552PQpY6SRsSfDxOWizRKjNzVA41oq%2FCnmo41uyFKHbr4hgqEwIpCXetSKuAXi1MSCYJRDsXWQJZq\"}],\"group\":\"cf-nel\",\"max_age\":604800}',\n",
      "    server: 'cloudflare',\n",
      "    'strict-transport-security': 'max-age=2592000; includeSubDomains',\n",
      "    'transfer-encoding': 'chunked',\n",
      "    vary: 'Accept-Encoding',\n",
      "    via: '1.1 465fd463b8e31c8b402f3b1a6398314c.cloudfront.net (CloudFront)',\n",
      "    'x-amz-cf-id': 'thoh3DfHpH7KNSLJ1hrtvB72eVBcp385qIKGx2XbELYdbgubWCyBDw==',\n",
      "    'x-amz-cf-pop': 'SFO53-P1',\n",
      "    'x-bt-cached': 'MISS',\n",
      "    'x-cache': 'Error from cloudfront',\n",
      "    'x-cached': 'false',\n",
      "    'x-frame-options': 'SAMEORIGIN'\n",
      "  },\n",
      "  request_id: undefined,\n",
      "  error: undefined,\n",
      "  code: undefined,\n",
      "  param: undefined,\n",
      "  type: undefined\n",
      "}\n",
      "InternalServerError: 520 <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.together.xyz | 520: Web server is returning an unknown error</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Web server is returning an unknown error</span>\n",
      "              <span class=\"code-label\">Error code 520</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2024-07-26 23:45:31 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">San Jose</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.together.xyz</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>There is an unknown connection issue between Cloudflare and the origin web server. As a result, the web page can not be displayed.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                          <h3 class=\"text-15 font-semibold mb-2\">If you are a visitor of this website:</h3>\n",
      "      <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "\n",
      "      <h3 class=\"text-15 font-semibold mb-2\">If you are the owner of this website:</h3>\n",
      "      <p><span>There is an issue between Cloudflare's cache and your origin web server. Cloudflare monitors for these errors and automatically investigates the cause. To help support the investigation, you can pull the corresponding error log from your web server and submit it our support team.  Please include the Ray ID (which is at the bottom of this error page).</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171936-Error-520\">Additional troubleshooting resources</a>.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">8a9843870046d01d</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">2a06:98c0:3600::103</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.together.xyz\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "    at APIError.generate (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/error.js:66:20)\n",
      "    at OpenAI.makeStatusError (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/core.js:275:33)\n",
      "    at OpenAI.makeRequest (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/openai@4.52.7/node_modules/openai/core.js:318:30)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5) {\n",
      "  status: 520,\n",
      "  headers: {\n",
      "    'cf-ray': '8a984380ee0bd01d-SJC',\n",
      "    connection: 'keep-alive',\n",
      "    'content-type': 'text/html; charset=UTF-8',\n",
      "    date: 'Fri, 26 Jul 2024 23:45:31 GMT',\n",
      "    nel: '{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}',\n",
      "    'referrer-policy': 'same-origin',\n",
      "    'report-to': '{\"endpoints\":[{\"url\":\"https:\\\\/\\\\/a.nel.cloudflare.com\\\\/report\\\\/v4?s=zNNmyIwWBP%2Fgd4fgXM8rf3ufQgazu4E0WPx8QLdYHelbYn5d6Wowvk6SISxPtk5lrJ2VrJaLbDBrhpddBRVI%2FWOWFNGVSO1fQFTi5Lq0UZgfpxWs%2F69MabpgZ5knvhVb4oQVgv4U\"}],\"group\":\"cf-nel\",\"max_age\":604800}',\n",
      "    server: 'cloudflare',\n",
      "    'strict-transport-security': 'max-age=2592000; includeSubDomains',\n",
      "    'transfer-encoding': 'chunked',\n",
      "    vary: 'Accept-Encoding',\n",
      "    via: '1.1 03f8f74b004ca394f25d22fb1ad4a310.cloudfront.net (CloudFront)',\n",
      "    'x-amz-cf-id': 'iA1GOvlrzxHwWZmKfD8PT8powNQ1Q2xypyJOHNPm6Zik08Xyq6QzQA==',\n",
      "    'x-amz-cf-pop': 'SFO53-P1',\n",
      "    'x-bt-cached': 'MISS',\n",
      "    'x-cache': 'Error from cloudfront',\n",
      "    'x-cached': 'false',\n",
      "    'x-frame-options': 'SAMEORIGIN'\n",
      "  },\n",
      "  request_id: undefined,\n",
      "  error: undefined,\n",
      "  code: undefined,\n",
      "  param: undefined,\n",
      "  type: undefined\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-571db11f compared to meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo-49a4defb:\n",
      "74.41% 'NumericDiff' score\t(0 improvements, 0 regressions)\n",
      "68.97% 'NonNull'     score\t(0 improvements, 0 regressions)\n",
      "\n",
      "8.31s 'duration'      \t(21 improvements, 39 regressions)\n",
      "0.00$ 'estimated_cost'\t(0 improvements, 0 regressions)\n",
      "\n",
      "See results for meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-571db11f at https://www.braintrust.dev/app/braintrustdata.com/p/LLaMa-3.1-Tools/experiments/meta-llama%2FMeta-Llama-3.1-8B-Instruct-Turbo-571db11f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://www.braintrust.dev/api/experiment/register\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://www.braintrust.dev/api/base_experiment/get_id\n",
      "RUNNING GET WITH URL https://d3p9hsahjc1cvu.cloudfront.net/experiment-comparison2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ████████████████████████░░░░░░░░░░░░░░░░ | LLaMa-3.1-Tools [experimentName=meta-... |  60% | 60/100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo-0f22d98e compared to meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-571db11f:\n",
      "82.69% (+8.28%) 'NumericDiff' score\t(19 improvements, 2 regressions)\n",
      "86.67% (+17.70%) 'NonNull'     score\t(15 improvements, 5 regressions)\n",
      "\n",
      "4.69s 'duration'      \t(44 improvements, 16 regressions)\n",
      "0.00$ 'estimated_cost'\t(0 improvements, 56 regressions)\n",
      "\n",
      "See results for meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo-0f22d98e at https://www.braintrust.dev/app/braintrustdata.com/p/LLaMa-3.1-Tools/experiments/meta-llama%2FMeta-Llama-3.1-70B-Instruct-Turbo-0f22d98e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://www.braintrust.dev/api/experiment/register\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Expected double-quoted property name in JSON at position 36 (line 1 column 37)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at Proxy.LLaMaFactuality (evalmachine.<anonymous>:98:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async Object.task (evalmachine.<anonymous>:5:33)\n",
      "    at async rootSpan.traced.name (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4552:26)\n",
      "    at async callback (/Users/ankur/projects/braintrust/sdk/js/dist/index.js:4548:11)\n",
      "    at async /Users/ankur/projects/braintrust/sdk/js/dist/index.js:4683:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://www.braintrust.dev/api/base_experiment/get_id\n",
      "RUNNING GET WITH URL https://d3p9hsahjc1cvu.cloudfront.net/experiment-comparison2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ████████████████████████░░░░░░░░░░░░░░░░ | LLaMa-3.1-Tools [experimentName=meta-... |  60% | 60/100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo-b2e826c2 compared to meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo-0f22d98e:\n",
      "87.87% (+5.18%) 'NumericDiff' score\t(6 improvements, 2 regressions)\n",
      "88.33% (+1.67%) 'NonNull'     score\t(6 improvements, 5 regressions)\n",
      "\n",
      "7.73s 'duration'      \t(20 improvements, 40 regressions)\n",
      "0.00$ 'estimated_cost'\t(0 improvements, 60 regressions)\n",
      "\n",
      "See results for meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo-b2e826c2 at https://www.braintrust.dev/app/braintrustdata.com/p/LLaMa-3.1-Tools/experiments/meta-llama%2FMeta-Llama-3.1-405B-Instruct-Turbo-b2e826c2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for (const model of [LLAMA31_8B, LLAMA31_70B, LLAMA31_405B]) {\n",
    "  await Eval(\"LLaMa-3.1-Tools\", {\n",
    "    data: data,\n",
    "    task: async (input) => (await LLaMaFactuality({ model, ...input }))?.score,\n",
    "    scores: [NumericDiff, NonNull],\n",
    "    experimentName: model,\n",
    "    metadata: {\n",
    "      model,\n",
    "    },\n",
    "  });\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1366d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    input: {\n",
      "      input: 'Who are the two boxer featured in this article?',\n",
      "      output: 'Floyd Mayweather and Manny Pacquiao',\n",
      "      expected: 'Floyd Mayweather and Manny Pacquiao'\n",
      "    },\n",
      "    expected: 1,\n",
      "    metadata: {\n",
      "      source: 'cnn',\n",
      "      story: \"(CNN)A chiseled boxer's Instagram feed shows him making constant references to the Bible and enjoying gospel singing with his wife. \\n\" +\n",
      "        '\\n' +\n",
      "        'Another features his formidable opponent counting stacks of money, hanging out in strip clubs, and flashing diamond watches and Ferraris. \\n' +\n",
      "        '\\n' +\n",
      "        'Welcome to the world of boxing promotion, circa 2015. \\n' +\n",
      "        '\\n' +\n",
      "        'American Floyd Mayweather and Filipino Manny Pacquiao are set to officially announce their heavily anticipated boxing match at a press conference in Los Angeles Wednesday. \\n' +\n",
      "        '\\n' +\n",
      "        'With the combined purse for the May 2 bout in Las Vegas reported to touch $300 million pending viewership numbers, the incentives to self-promote could not be higher. \\n' +\n",
      "        '\\n' +\n",
      "        `\"Nowadays you have to be on social media to launch the fight and to build hype,\" says boxing promoter Nisse Sauerland, CEO of Team Sauerland. \"It couldn't be done without it.\" \\n` +\n",
      "        '\\n' +\n",
      "        'Thirty-eight year old Mayweather (47-0, 26 knockouts), who favors the moniker \"The Money Man\" or \"TBE\" (The Best Ever), boasts nearly five million Instagram followers, 5.65 million followers on Twitter and 9.2 million Facebook likes. \\n' +\n",
      "        '\\n' +\n",
      "        \"He famously confirmed the fight via Shots, a photo sharing social media application that he's invested in, and displays links to his clothing brand, The Money Team, on all his accounts. \\n\" +\n",
      "        '\\n' +\n",
      "        'Along with professing to the be the best fighter of all time, he could also stake a claim to be one of the greatest social media users in sports. \\n' +\n",
      "        '\\n' +\n",
      "        `\"I think they're both playing their roles,\" says Sauerland, who promotes over 45 boxers. \"You've got the bad guy and the good guy, really. You've got the guy who throws the money around (Mayweather), that's his image, and Pacquiao, he's the hope of a nation.\" `,\n",
      "      questions: [Array],\n",
      "      answers: [Object]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    input: {\n",
      "      input: 'Where do Quinton and Kendra travel to and from every day?',\n",
      "      output: \"No school go to Quentin's house\",\n",
      "      expected: 'school'\n",
      "    },\n",
      "    expected: 0.6,\n",
      "    metadata: {\n",
      "      source: 'mctest',\n",
      "      story: \"Kendra and Quinton travel to and from school every day. Kendra lives further from the bus stop than Quinton does, stops every morning at Quinton's house to join him to walk to the bus stop. Every afternoon, after school, when walking home from the bus stop they go in for cookies and milk that Quinton's mother has ready and waiting for them. Quinton can't eat cheese or cake so they had the same snack every day. They both work together on their homework and when they are done they play together. Kendra always makes sure to leave in time to get home for dinner. She doesn't want to miss story time which was right before bedtime. \\n\" +\n",
      "        '\\n' +\n",
      "        \"One morning Kendra walked up to Quinton's house, she thought something might be wrong because normally Quinton was waiting outside for her and on this morning he was not to be found. Kendra went up to the door and knocked. She waited and waited and yet no one answered. She saw that Quinton's mother's car wasn't in their driveway which was weird. She waited for a few bit looking up and down the block and getting worried when Quinton was nowhere to be found. \\n\" +\n",
      "        '\\n' +\n",
      "        \"Kendra didn't want to miss the bus to school and hurried off to make it in time. The bus driver saw that she was upset and that Quinton was not with her that morning. She told him what happened and he said that he was sure that everything would be okay. \\n\" +\n",
      "        '\\n' +\n",
      "        \"Kendra got to school, ran to her teacher and told him what happened that morning. The teacher smiled and told her not to worry, Quinton's mother had called and he was going to the dentist and would be at school after lunch and that she would see him at the bus stop like normal tomorrow.\",\n",
      "      questions: [Array],\n",
      "      answers: [Object]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    input: {\n",
      "      input: 'Is someone in showbiz?',\n",
      "      output: 'Dennis Farina Yes. Actor',\n",
      "      expected: 'Yes.'\n",
      "    },\n",
      "    expected: 0.6,\n",
      "    metadata: {\n",
      "      source: 'cnn',\n",
      "      story: '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n' +\n",
      "        '\\n' +\n",
      "        '\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n' +\n",
      "        '\\n' +\n",
      "        'Farina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n' +\n",
      "        '\\n' +\n",
      "        'Farina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n' +\n",
      "        '\\n' +\n",
      "        `In 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach's departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach's rumpled Lennie Briscoe. \\n` +\n",
      "        '\\n' +\n",
      "        `Farina was on \"Law & Order\" for two years, partnered with Jesse L. Martin's Ed Green. Martin's character became a senior detective after Farina left the show. `,\n",
      "      questions: [Array],\n",
      "      answers: [Object]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    input: {\n",
      "      input: 'How many burroughs are there?',\n",
      "      output: 'five',\n",
      "      expected: 'five'\n",
      "    },\n",
      "    expected: 1,\n",
      "    metadata: {\n",
      "      source: 'wikipedia',\n",
      "      story: 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n' +\n",
      "        '\\n' +\n",
      "        \"The North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul's Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.\",\n",
      "      questions: [Array],\n",
      "      answers: [Object]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    input: {\n",
      "      input: 'Which country consumes tea the most?',\n",
      "      output: 'Great Britain',\n",
      "      expected: 'Great Britain'\n",
      "    },\n",
      "    expected: 1,\n",
      "    metadata: {\n",
      "      source: 'race',\n",
      "      story: \"Which country grows the most tea? The answer is India. It grows three times as much as China. Which country drinks the most tea? It's neither China nor Japan. It's Great Britain. In the wild, tea plants may be 30 feet tall. But a plant grown for market is pruned. Pruning keeps the plant only three or four feet tall. This is an easy height for tea picking. Only the two top leaves and bud of each new shoot are picked. So to make money, tea plantations must be huge. In general, there are two kinds of tea. Black tea and green tea. Black tea is fermented. In the process, the tea loses nearly all of its healthy qualities. Green tea is steamed right after the leaves are picked. Green tea _ its healthy qualities. For example, it may prevent heart disease. How did we get tea bag? The answer: by accident. Tea merchants used to send samples in tin boxes. This was costly. One merchant thought of a cheaper way. He sent samples in small silk bags. Customers would cut open the bag. They would brew the leaves as usual. One customer put the bag into a pot. Then he just poured hot water over it. And the tea bag was born. Shen Nong was the first to drink tea. (Shen was a Chinese emperor.) This was about 2737 B.C. Shen had bad digestion. So he drank several cups of hot water daily. One day something happened. Leaves from a wild tea tree fell into the hot water pot. The next cup was poured. The water was now colored. Shen sipped it. He liked it. He drank it all. Shen was proud of his new drink. He served it to his guests. Word spread. People thought this way. Tea is good enough for the Emperor. So it must be good enough for the people. Tea became the drink of China.\",\n",
      "      questions: [Array],\n",
      "      answers: [Object]\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "// Pick 10 random examples from data\n",
    "const examples = [...data];\n",
    "examples.sort(() => Math.random() - 0.5);\n",
    "console.log(examples.slice(0, 5));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "282f7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {\"input\":\"Who are the two boxer featured in this article?\",\"output\":\"Floyd Mayweather and Manny Pacquiao\",\"expected\":\"Floyd Mayweather and Manny Pacquiao\"}\n",
      "Output: {\"choice\":\"E\",\"reasons\":\"The answer is correct\"}    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "// NOTE: We don't have expected rationales\n",
    "const invertedChoiceScores = Object.fromEntries(\n",
    "  Object.entries(template.choice_scores).map(([choice, score]) => [\n",
    "    score,\n",
    "    choice,\n",
    "  ])\n",
    ");\n",
    "\n",
    "function formatExample(example: CoqaCase) {\n",
    "  return `Input: ${JSON.stringify(example.input)}\n",
    "Output: ${JSON.stringify({ choice: invertedChoiceScores[example.expected], reasons: example.expected === 1 ? \"The answer is correct\" : example.expected === 0 ? \"The answer is irrelevant and non overlapping\" : \"The answer is a superset of the expected value\" })}    \n",
    "`;\n",
    "}\n",
    "\n",
    "formatExample(examples[0]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cf3d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function=select_choice>{\"choice\":\"E\",\"reasons\":\"The submitted answer is a superset of the expert answer and is fully consistent with it.\"}</function>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error parsing function arguments: SyntaxError: Unexpected non-whitespace character after JSON at position 115 (line 1 column 116)\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at Proxy.parseToolResponse (evalmachine.<anonymous>:9:31)\n",
      "    at LLaMaFactuality (evalmachine.<anonymous>:47:32)\n",
      "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
      "    at async evalmachine.<anonymous>:69:34\n",
      "    at async Object.execute (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/tslab@1.0.21/node_modules/tslab/dist/executor.js:173:17)\n",
      "    at async JupyterHandlerImpl.handleExecuteImpl (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/tslab@1.0.21/node_modules/tslab/dist/jupyter.js:223:18)\n",
      "    at async JupyterHandlerImpl.handleExecute (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/tslab@1.0.21/node_modules/tslab/dist/jupyter.js:181:21)\n",
      "    at async ZmqServer.handleExecute (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/tslab@1.0.21/node_modules/tslab/dist/jupyter.js:379:25)\n",
      "    at async ZmqServer.handleShellMessage (/Users/ankur/projects/braintrust/cookbook/content/node_modules/.pnpm/tslab@1.0.21/node_modules/tslab/dist/jupyter.js:324:21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  name: 'Factuality',\n",
      "  score: undefined,\n",
      "  metadata: { rationale: undefined, choice: undefined }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async function LLaMaFactuality({\n",
    "  model,\n",
    "  input,\n",
    "  output,\n",
    "  expected,\n",
    "}: {\n",
    "  model: string;\n",
    "  input: string;\n",
    "  output: string;\n",
    "  expected: string;\n",
    "}) {\n",
    "  const toolPrompt = `You have access to the following functions:\n",
    "\n",
    "Use the function '${selectTool.name}' to '${selectTool.description}':\n",
    "${JSON.stringify(selectTool)}\n",
    "\n",
    "If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n",
    "\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
    "\n",
    "Reminder:\n",
    "- If looking for real time information use relevant functions before falling back to brave_search\n",
    "- Function calls MUST follow the specified format, start with <function= and end with </function>\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "  `;\n",
    "\n",
    "  const response = await client.chat.completions.create({\n",
    "    model,\n",
    "    messages: [\n",
    "      {\n",
    "        role: \"system\",\n",
    "        content: toolPrompt,\n",
    "      },\n",
    "      {\n",
    "        role: \"user\",\n",
    "        content: mustache.render(template.prompt, {\n",
    "          input,\n",
    "          output,\n",
    "          expected,\n",
    "        }),\n",
    "      },\n",
    "      {\n",
    "        role: \"user\",\n",
    "        content: `Here are a few examples:\n",
    "\n",
    "${examples.map(formatExample).join(\"\\n\")}`,\n",
    "      },\n",
    "    ],\n",
    "    temperature: 0,\n",
    "    max_tokens: 2048,\n",
    "  });\n",
    "\n",
    "  try {\n",
    "    console.log(response.choices[0].message.content);\n",
    "    const parsed = parseToolResponse(response.choices[0].message.content);\n",
    "    return {\n",
    "      name: \"Factuality\",\n",
    "      score: template.choice_scores[parsed?.args.choice],\n",
    "      metadata: {\n",
    "        rationale: parsed?.args.reasons,\n",
    "        choice: parsed?.args.choice,\n",
    "      },\n",
    "    };\n",
    "  } catch (e) {\n",
    "    console.error(e);\n",
    "    return {\n",
    "      name: \"Factuality\",\n",
    "      score: null,\n",
    "      metadata: {\n",
    "        error: `${e}`,\n",
    "      },\n",
    "    };\n",
    "  }\n",
    "}\n",
    "\n",
    "console.log(\n",
    "  await LLaMaFactuality({\n",
    "    model: LLAMA31_8B,\n",
    "    input: \"What is the weather in Tokyo?\",\n",
    "    output: \"The weather in Tokyo is scorching.\",\n",
    "    expected: \"The weather in Tokyo is extremely hot.\",\n",
    "  })\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9e3855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING POST WITH URL https://www.braintrust.dev/api/experiment/register\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://d3p9hsahjc1cvu.cloudfront.net/logs3\n",
      "RUNNING POST WITH URL https://www.braintrust.dev/api/base_experiment/get_id\n",
      "RUNNING GET WITH URL https://d3p9hsahjc1cvu.cloudfront.net/experiment-comparison2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ████████████████████████░░░░░░░░░░░░░░░░ | LLaMa-3.1-Tools [experimentName=meta-... |  60% | 60/100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-few-shot-no-cot compared to meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-few-shot:\n",
      "65.36% (-7.74%) 'NumericDiff' score\t(8 improvements, 16 regressions)\n",
      "100.00% (+21.67%) 'NonNull'     score\t(13 improvements, 0 regressions)\n",
      "\n",
      "3.20s 'duration'      \t(32 improvements, 28 regressions)\n",
      "0.00$ 'estimated_cost'\t(3 improvements, 0 regressions)\n",
      "\n",
      "See results for meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-few-shot-no-cot at https://www.braintrust.dev/app/braintrustdata.com/p/LLaMa-3.1-Tools/experiments/meta-llama%2FMeta-Llama-3.1-8B-Instruct-Turbo-few-shot-no-cot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "const selectTool = {\n",
    "  name: \"select_choice\",\n",
    "  description: \"Call this function to select a choice.\",\n",
    "  parameters: {\n",
    "    properties: {\n",
    "      reasons: {\n",
    "        description:\n",
    "          \"Write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.\",\n",
    "        title: \"Reasoning\",\n",
    "        type: \"string\",\n",
    "      },\n",
    "      choice: {\n",
    "        description: \"The choice\",\n",
    "        title: \"Choice\",\n",
    "        type: \"string\",\n",
    "        enum: Object.keys(template.choice_scores),\n",
    "      },\n",
    "    },\n",
    "    required: [\"reasons\", \"choice\"],\n",
    "    title: \"CoTResponse\",\n",
    "    type: \"object\",\n",
    "  },\n",
    "};\n",
    "\n",
    "for (const model of [LLAMA31_8B /*, LLAMA31_70B, LLAMA31_405B*/]) {\n",
    "  await Eval(\"LLaMa-3.1-Tools\", {\n",
    "    data: data,\n",
    "    task: async (input) => (await LLaMaFactuality({ model, ...input }))?.score,\n",
    "    scores: [NumericDiff, NonNull],\n",
    "    experimentName: `${model}-few-shot`,\n",
    "    metadata: {\n",
    "      model,\n",
    "    },\n",
    "  });\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c0f65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53783a49-1c41-4668-92e3-142887534c00",
   "metadata": {},
   "source": [
    "## Where to go from here\n",
    "\n",
    "In just a few minutes, we've cracked the code on how to perform tool calls with LLaMa-3.1 models and run a benchmark to compare their performance to GPT-4o. In doing so, we've\n",
    "found a few specific areas for improvement, e.g. parsing errors for tool calls, and a surprising outcome that LLaMa-3.1-70B is better than both LLaMa-3.1-405B and GPT-4o, yet a\n",
    "fraction of the cost.\n",
    "\n",
    "To explore this further, you could:\n",
    "\n",
    "- Expand the benchmark to measure other kinds of evaluators.\n",
    "- Try providing few-shot examples or fine-tuning the models to improve their performance.\n",
    "- Play with other models, like GPT-4o-mini or Claude to see how they compare.\n",
    "\n",
    "Happy evaluating!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
