{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a reliable agent for interacting with an API\n",
    "\n",
    "We're going to build an agent that can interact with users to run complex commands against a custom API. For this example, we'll use the Braintrust API, which has an easy\n",
    "to work with [OpenAPI spec](https://github.com/braintrustdata/braintrust-openapi).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by installing dependencies and setting up our OpenAI and Braintrust environments.\n",
    "\n",
    "Before getting started, make sure you have a [Braintrust account](https://www.braintrust.dev/signup) and an API key for [OpenAI](https://platform.openai.com/). Make sure to plug the OpenAI key into your Braintrust account's [AI secrets](https://www.braintrust.dev/app/settings?subroute=secrets) configuration and acquire a [BRAINTRUST_API_KEY](https://www.braintrust.dev/app/settings?subroute=api-keys). Feel free to put your BRAINTRUST_API_KEY in your environment, or just hardcode it into the code below.\n",
    "\n",
    "### Install dependencies\n",
    "\n",
    "We're not going to use any frameworks or complex dependencies to keep things simple and literate. Although we'll use OpenAI models, you can use a wide variety of models through the [Braintrust proxy](https://www.braintrust.dev/docs/guides/proxy) without having to write model-specific code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U autoevals braintrust jsonref openai numpy pydantic requests tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup libraries\n",
    "\n",
    "Next, let's wire up the OpenAI and Braintrust clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import braintrust\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "BRAINTRUST_API_KEY = os.environ.get(\"BRAINTRUST_API_KEY\") # Or hardcode this to your API key\n",
    "OPENAI_BASE_URL = \"https://api.braintrust.dev/v1/proxy\" # You can use your own base URL / proxy\n",
    "\n",
    "braintrust.login() # This is optional, but makes it easier to grab the api url (and other variables) later on\n",
    "\n",
    "client = braintrust.wrap_openai(AsyncOpenAI(\n",
    "    api_key=BRAINTRUST_API_KEY,\n",
    "    base_url=OPENAI_BASE_URL,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the OpenAPI spec\n",
    "\n",
    "Let's download the Braintrust OpenAPI spec, and break it into pieces that we'll embed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonref\n",
    "import requests\n",
    "\n",
    "base_spec = requests.get(\"https://raw.githubusercontent.com/braintrustdata/braintrust-openapi/main/openapi/spec.json\").json()\n",
    "\n",
    "# Flatten out refs so we have self-contained descriptions\n",
    "spec = jsonref.loads(jsonref.dumps(base_spec))\n",
    "paths = spec['paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around a bit with the data to understand the types of API requests we can run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Create a new project. If there is an existing project with the same name as the one specified in the request, will return the existing project unmodified\n",
      "Parameters:  {\n",
      "  \"description\": \"Any desired information about the new project object\",\n",
      "  \"required\": false,\n",
      "  \"content\": {\n",
      "    \"application/json\": {\n",
      "      \"schema\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"name\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the project\"\n",
      "          },\n",
      "          \"org_name\": {\n",
      "            \"type\": \"string\",\n",
      "            \"nullable\": true,\n",
      "            \"description\": \"For nearly all users, this parameter should be unnecessary. But in the rare case that your API key belongs to multiple organizations, you may specify the name of the organization the project belongs in.\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"name\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Description: \", paths['/v1/project']['post']['description'])\n",
    "print(\"Parameters: \", json.dumps(paths['/v1/project']['post']['requestBody'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. This looks like useful information to know when to use this API endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num paths 49\n",
      "Num operations 95\n",
      "Paths text size 157189\n",
      "Num tokens 39467\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "operations = [(path, op) for (path, ops) in paths.items() for (op_type, op) in ops.items() if op_type != \"options\"]\n",
    "\n",
    "print(\"Num paths\", len(paths))\n",
    "print(\"Num operations\", len(operations))\n",
    "print(\"Paths text size\", len(jsonref.dumps(operations)))\n",
    "print(\"Num tokens\", len(tiktoken.encoding_for_model(\"gpt-4o\").encode(jsonref.dumps(operations))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the embeddings\n",
    "\n",
    "Although this could theoretically fit in a single prompt (at only around 50,000 tokens vs. the 128,000 token limit for gpt-4o), let's embed each operation instead.\n",
    "\n",
    "We'll start by creating a simple function to describe each API operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Create project\n",
      "\n",
      "Create a new project. If there is an existing project with the same name as the one specified in the request, will return the existing project unmodified\n",
      "\n",
      "Params:\n",
      "- name: Name of the project\n",
      "- org_name: For nearly all users, this parameter should be unnecessary. But in the rare case that your API key belongs to multiple organizations, you may specify the name of the organization the project belongs in.\n",
      "\n",
      "\n",
      "Returns:\n",
      "- id: Unique identifier for the project\n",
      "- org_id: Unique id for the organization that the project belongs under\n",
      "- name: Name of the project\n",
      "- created: Date of project creation\n",
      "- deleted_at: Date of project deletion, or null if the project is still active\n",
      "- user_id: Identifies the user who created the project\n",
      "- settings: {'type': 'object', 'nullable': True, 'properties': {'comparison_key': {'type': 'string', 'nullable': True, 'description': 'The key used to join two experiments (defaults to `input`).'}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def has_path(d, path):\n",
    "    curr = d\n",
    "    for p in path:\n",
    "        if p not in curr:\n",
    "            return False\n",
    "        curr = curr[p]\n",
    "    return True\n",
    "\n",
    "def make_description(op):\n",
    "    return f\"\"\"# {op['summary']}\n",
    "\n",
    "{op['description']}\n",
    "\n",
    "Params:\n",
    "{\"\\n\".join([f\"- {name}: {p.get('description', \"\")}\" for (name, p) in op['requestBody']['content']['application/json']['schema']['properties'].items()]) if has_path(op, ['requestBody', 'content', 'application/json', 'schema', 'properties']) else \"\"}\n",
    "{\"\\n\".join([f\"- {p.get(\"name\")}: {p.get('description', \"\")}\" for p in op['parameters'] if p.get(\"name\")]) if has_path(op, ['parameters']) else \"\"}\n",
    "\n",
    "Returns:\n",
    "{\"\\n\".join([f\"- {name}: {p.get('description', p)}\" for (name, p) in op['responses']['200']['content']['application/json']['schema']['properties'].items()]) if has_path(op, ['responses', '200', 'content', 'application/json', 'schema', 'properties']) else \"empty\"}\n",
    "\"\"\"\n",
    "\n",
    "print(make_description(operations[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Any\n",
    "\n",
    "class Document(BaseModel):\n",
    "    path: str\n",
    "    op: str\n",
    "    definition: Any\n",
    "    description: str\n",
    "\n",
    "documents = [Document(path=path, op=op_type, definition=json.loads(jsonref.dumps(op)), description=make_description(op)) for (path, ops) in paths.items() for (op_type, op) in ops.items() if op_type != \"options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def make_embedding(doc: Document):\n",
    "    return (await client.embeddings.create(input=doc.description, model=\"text-embedding-3-small\")).data[0].embedding\n",
    "\n",
    "embeddings = await asyncio.gather(*[make_embedding(doc) for doc in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search\n",
    "\n",
    "We're going to use `numpy` to do the vector search, but you can easily swap this out to a vector database of your choice!.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(query_embedding, embedding_matrix):\n",
    "    # Normalize the query and matrix embeddings\n",
    "    query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "    matrix_norm = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute dot product\n",
    "    similarities = np.dot(matrix_norm, query_norm)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "def find_k_most_similar(query_embedding, embedding_matrix, k=5):\n",
    "    similarities = cosine_similarity(query_embedding, embedding_matrix)\n",
    "    top_k_indices = np.argpartition(similarities, -k)[-k:]\n",
    "    top_k_similarities = similarities[top_k_indices]\n",
    "    \n",
    "    # Sort the top k results\n",
    "    sorted_indices = np.argsort(top_k_similarities)[::-1]\n",
    "    top_k_indices = top_k_indices[sorted_indices]\n",
    "    top_k_similarities = top_k_similarities[sorted_indices]\n",
    "    \n",
    "    return list([index, similarity] for (index, similarity) in zip(top_k_indices, top_k_similarities))\n",
    "\n",
    "\n",
    "embedding_matrix = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braintrust import traced\n",
    "from pydantic import Field\n",
    "from typing import List\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    document: Document\n",
    "    index: int\n",
    "    similarity: float\n",
    "\n",
    "class SearchResults(BaseModel):\n",
    "    results: List[SearchResult]\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    query: str\n",
    "    top_k: int = Field(default=3, le=5)\n",
    "\n",
    "# This @traced decorator will help us trace this function when we use it later to run evals\n",
    "@traced\n",
    "async def search(query: SearchQuery):\n",
    "    query_embedding = (await client.embeddings.create(input=query.query, model=\"text-embedding-3-small\")).data[0].embedding\n",
    "    results = find_k_most_similar(query_embedding, embedding_matrix, k=query.top_k)\n",
    "    return SearchResults(results=[SearchResult(document=documents[index], index=index, similarity=similarity) for (index, similarity) in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/v1/project post 0.44983070105606093\n",
      "/v1/project_tag post 0.3720152521991169\n",
      "/v1/project_score post 0.35847367063785307\n"
     ]
    }
   ],
   "source": [
    "for result in (await search(SearchQuery(query=\"create a new project\"))).results:\n",
    "    print(result.document.path, result.document.op, result.similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the chat agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can search for documents, let's build a chat agent that can search for documents and run API commands. Our chat bot will have\n",
    "two tools:\n",
    "\n",
    "- `search`: This tool will search for documents and return the most relevant ones.\n",
    "- `run_command`: This tool will run an API command.\n",
    "\n",
    "We already implemented `search` above, so let's start by just plugging in the chat implementation to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = {\n",
    "    \"search\": (SearchQuery, search),\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Search for API endpoints related to the query\",\n",
    "            \"parameters\": SearchQuery.model_json_schema()\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "MAX_TOOL_STEPS = 3\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are a helpful assistant that can answer questions about Braintrust, a tool for\n",
    "developing AI applications. Braintrust can help with evals, observability, and prompt\n",
    "development.\n",
    "\n",
    "If you don't know how to answer the question based on information you have, make up\n",
    "endpoints and suggest running them. I'm sure they'll exist!\n",
    "\"\"\"\n",
    "\n",
    "@traced\n",
    "async def perform_chat_step(message, history=None):\n",
    "    chat_history = list(history or [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]) + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    for _ in range(MAX_TOOL_STEPS):\n",
    "        result = (await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=chat_history,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0,\n",
    "        )).choices[0].message\n",
    "\n",
    "        chat_history.append(result)\n",
    "\n",
    "\n",
    "        if not result.tool_calls:\n",
    "            break\n",
    "\n",
    "        tool_call = result.tool_calls[0]\n",
    "        ArgClass, tool_func = tool_registry[tool_call.function.name]\n",
    "        args = tool_call.function.arguments\n",
    "        args = ArgClass.model_validate_json(args)\n",
    "        result = await tool_func(args)\n",
    "\n",
    "        chat_history.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": json.dumps(result.model_dump())\n",
    "        })\n",
    "    else:\n",
    "        raise Exception(\"Ran out of tool steps\")\n",
    "\n",
    "    return chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a new project in Braintrust, you can use the following endpoint:\n",
      "\n",
      "### Endpoint\n",
      "**POST** `/v1/project`\n",
      "\n",
      "### Description\n",
      "Create a new project. If there is an existing project with the same name as the one specified in the request, it will return the existing project unmodified.\n",
      "\n",
      "### Parameters\n",
      "- **name**: Name of the project (required)\n",
      "- **org_name**: For nearly all users, this parameter should be unnecessary. But in the rare case that your API key belongs to multiple organizations, you may specify the name of the organization the project belongs in.\n",
      "\n",
      "### Response\n",
      "- **id**: Unique identifier for the project\n",
      "- **org_id**: Unique id for the organization that the project belongs under\n",
      "- **name**: Name of the project\n",
      "- **created**: Date of project creation\n",
      "- **deleted_at**: Date of project deletion, or null if the project is still active\n",
      "- **user_id**: Identifies the user who created the project\n",
      "- **settings**: Object containing project settings\n",
      "\n",
      "### Example Request\n",
      "```json\n",
      "{\n",
      "  \"name\": \"My New Project\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Example Response\n",
      "```json\n",
      "{\n",
      "  \"id\": \"project_id\",\n",
      "  \"org_id\": \"organization_id\",\n",
      "  \"name\": \"My New Project\",\n",
      "  \"created\": \"2023-10-01T00:00:00Z\",\n",
      "  \"deleted_at\": null,\n",
      "  \"user_id\": \"user_id\",\n",
      "  \"settings\": {\n",
      "    \"comparison_key\": \"input\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Would you like to proceed with creating a new project? If so, please provide the project name and any other relevant details.\n"
     ]
    }
   ],
   "source": [
    "@traced\n",
    "async def run_full_inqiry(query: str):  \n",
    "    return (await perform_chat_step(query))[-1].content\n",
    "\n",
    "print(await run_full_inqiry(\"how do i create a new project?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 2 equals 3.\n"
     ]
    }
   ],
   "source": [
    "print(await run_full_inqiry(\"what is 1+2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding observability to generate eval data\n",
    "\n",
    "Now that we have a basic chat agent, let's try adding observability via Braintrust. The good news is that... we don't need to write a single line of code! By adding the `@traced` decorators\n",
    "and `wrap_openai`, we have done all the work we need.\n",
    "\n",
    "By simply initializing a logger, we turn on logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<braintrust.logger.Logger at 0x125859700>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "braintrust.init_logger(\"APIAgent\") # Feel free to replace this a project name of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how do i list my last 20 experiments?\n",
      "To list your last 20 experiments, you can use the `GET /v1/experiment` endpoint. This endpoint allows you to list all experiments, sorted by creation date with the most recently-created experiments coming first. You can limit the number of experiments returned by using the `limit` parameter.\n",
      "\n",
      "Here is an example of how you can call this endpoint to get the last 20 experiments:\n",
      "\n",
      "```\n",
      "GET /v1/experiment?limit=20\n",
      "```\n",
      "\n",
      "This will return a list of the 20 most recent experiments.\n",
      "---------------\n",
      "Question: How do I deploy my frontend web app through Braintrust?\n",
      "It seems there isn't a specific endpoint or documentation directly related to deploying a frontend web app through Braintrust. However, you can use Braintrust for various tasks such as evaluations, observability, and prompt development.\n",
      "\n",
      "To deploy a frontend web app, you might need to follow general deployment practices using other tools or platforms like Vercel, Netlify, or AWS. If you have specific requirements or need to integrate with Braintrust for certain functionalities, you can explore the available endpoints and see how they can be utilized in your deployment process.\n",
      "\n",
      "If you have any other specific questions or need further assistance with Braintrust, feel free to ask!\n",
      "---------------\n",
      "Question: How do I create a new project?\n",
      "To create a new project in Braintrust, you can use the following endpoint:\n",
      "\n",
      "### Endpoint\n",
      "**POST** `/v1/project`\n",
      "\n",
      "### Description\n",
      "Create a new project. If there is an existing project with the same name as the one specified in the request, it will return the existing project unmodified.\n",
      "\n",
      "### Parameters\n",
      "- **name**: Name of the project (required)\n",
      "- **org_name**: For nearly all users, this parameter should be unnecessary. But in the rare case that your API key belongs to multiple organizations, you may specify the name of the organization the project belongs in.\n",
      "\n",
      "### Request Body\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Your Project Name\",\n",
      "  \"org_name\": \"Your Organization Name (optional)\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Responses\n",
      "- **200**: Returns the new project object\n",
      "- **400**: The request was unacceptable, often due to missing a required parameter\n",
      "- **401**: No valid API key provided\n",
      "- **403**: The API key doesn’t have permissions to perform the request\n",
      "- **429**: Too many requests hit the API too quickly. We recommend an exponential backoff of your requests\n",
      "- **500**: Something went wrong on Braintrust's end. (These are rare.)\n",
      "\n",
      "### Example Response\n",
      "```json\n",
      "{\n",
      "  \"id\": \"unique_project_id\",\n",
      "  \"org_id\": \"unique_org_id\",\n",
      "  \"name\": \"Your Project Name\",\n",
      "  \"created\": \"date_of_creation\",\n",
      "  \"deleted_at\": null,\n",
      "  \"user_id\": \"user_id_who_created_project\",\n",
      "  \"settings\": {\n",
      "    \"comparison_key\": \"input\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "You can use this endpoint to create a new project by sending a POST request with the required parameters.\n",
      "---------------\n",
      "Question: How do I download a specific dataset?\n",
      "To download a specific dataset, you can use the following endpoint:\n",
      "\n",
      "### Get Dataset by ID\n",
      "- **Endpoint:** `GET /v1/dataset/{dataset_id}`\n",
      "- **Description:** Get a dataset object by its ID.\n",
      "- **Parameters:**\n",
      "  - `dataset_id` (required): The unique identifier for the dataset.\n",
      "\n",
      "#### Example Request\n",
      "```http\n",
      "GET /v1/dataset/{dataset_id}\n",
      "Authorization: Bearer YOUR_API_KEY\n",
      "```\n",
      "\n",
      "#### Example Response\n",
      "```json\n",
      "{\n",
      "  \"id\": \"dataset_id\",\n",
      "  \"project_id\": \"project_id\",\n",
      "  \"name\": \"dataset_name\",\n",
      "  \"description\": \"Textual description of the dataset\",\n",
      "  \"created\": \"2023-10-01T00:00:00Z\",\n",
      "  \"deleted_at\": null,\n",
      "  \"user_id\": \"user_id\",\n",
      "  \"metadata\": {}\n",
      "}\n",
      "```\n",
      "\n",
      "This will return the dataset object, which you can then use to download the dataset.\n",
      "\n",
      "Would you like to proceed with downloading a specific dataset? If so, please provide the `dataset_id`.\n",
      "---------------\n",
      "Question: Can I create an evaluation through the API?\n",
      "Yes, you can create an evaluation through the API. The endpoint to launch an evaluation is:\n",
      "\n",
      "### Endpoint\n",
      "- **Path**: `/v1/eval`\n",
      "- **Method**: `POST`\n",
      "\n",
      "### Description\n",
      "Launch an evaluation by providing pointers to a dataset, task function, and scoring functions. The API will run the evaluation, create an experiment, and return the results along with a link to the experiment.\n",
      "\n",
      "### Parameters\n",
      "- **project_id**: Unique identifier for the project to run the eval in (required)\n",
      "- **data**: The dataset to use (required)\n",
      "  - Options:\n",
      "    - `dataset_id`: ID of the dataset\n",
      "    - `project_name` and `dataset_name`: Name of the project and dataset\n",
      "- **task**: The function to evaluate (required)\n",
      "  - Options:\n",
      "    - `function_id` and `version`: ID and version of the function\n",
      "    - `project_name`, `slug`, and `version`: Project name, slug, and version of the function\n",
      "    - `global_function`: Name of the global function\n",
      "    - `prompt_session_id`, `prompt_session_function_id`, and `version`: ID of the prompt session, function in the prompt session, and version\n",
      "- **scores**: The functions to score the eval on (required)\n",
      "  - Options:\n",
      "    - `function_id` and `version`: ID and version of the function\n",
      "    - `project_name`, `slug`, and `version`: Project name, slug, and version of the function\n",
      "    - `global_function`: Name of the global function\n",
      "    - `prompt_session_id`, `prompt_session_function_id`, and `version`: ID of the prompt session, function in the prompt session, and version\n",
      "- **experiment_name**: An optional name for the experiment created by this eval\n",
      "- **metadata**: Optional experiment-level metadata to store about the evaluation\n",
      "- **stream**: Whether to stream the results of the eval (boolean)\n",
      "\n",
      "### Response\n",
      "- **project_name**: Name of the project that the experiment belongs to\n",
      "- **experiment_name**: Name of the experiment\n",
      "- **project_url**: URL to the project's page in the Braintrust app\n",
      "- **experiment_url**: URL to the experiment's page in the Braintrust app\n",
      "- **comparison_experiment_name**: The experiment which scores are baselined against\n",
      "- **scores**: Summary of the experiment's scores\n",
      "- **metrics**: Summary of the experiment's metrics\n",
      "\n",
      "To use this endpoint, you would send a POST request with the required parameters in the request body.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "QUESTIONS = [\n",
    "    \"how do i list my last 20 experiments?\",\n",
    "    \"How do I deploy my frontend web app through Braintrust?\",\n",
    "    \"How do I create a new project?\",\n",
    "    \"How do I download a specific dataset?\",\n",
    "    \"Can I create an evaluation through the API?\"\n",
    "]\n",
    "\n",
    "for question in QUESTIONS:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(await run_full_inqiry(question))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting hallucinations\n",
    "\n",
    "Great, now that we've looked at the results, let's see if we can make our lives a bit easier by adding a hallucination score. That will help us\n",
    "pick out examples that are useful to test.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
