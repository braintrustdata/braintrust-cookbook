{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python requests datasets braintrust autoevals openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrian/braintrust/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Experiment mmvu_eval_32images is running at https://www.braintrust.dev/app/braintrustdata.com/p/mmvu_eval_32images/experiments/mmvu_eval_32images\n",
      "mmvu_eval_32images [experiment_name=mmvu_eval_32images] (data): 20it [00:00, 71943.46it/s]\n",
      "mmvu_eval_32images [experiment_name=mmvu_eval_32images] (tasks): 100%|██████████| 20/20 [00:23<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "mmvu_eval_32images compared to mmvu_eval_32images-fb15e25a:\n",
      "35.00% 'LLMJudge' score\n",
      "\n",
      "1739843539.26s start\n",
      "1739843556.42s end\n",
      "14.50s duration\n",
      "7.71s llm_duration\n",
      "2472.25tok prompt_tokens\n",
      "26.55tok completion_tokens\n",
      "2498.80tok total_tokens\n",
      "0.01$ estimated_cost\n",
      "\n",
      "See results for mmvu_eval_32images at https://www.braintrust.dev/app/braintrustdata.com/p/mmvu_eval_32images/experiments/mmvu_eval_32images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import braintrust\n",
    "import autoevals\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "NUM_FRAMES = 32\n",
    "TARGET_DIMENSIONS = (512, 512)\n",
    "JPEG_QUALITY = 80\n",
    "\n",
    "RETRY_TOTAL = 3\n",
    "RETRY_BACKOFF = 0.5\n",
    "STATUS_FORCELIST = [502, 503, 504]\n",
    "\n",
    "os.environ[\"BRAINTRUST_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "client = braintrust.wrap_openai(\n",
    "    OpenAI(\n",
    "        api_key=os.environ[\"BRAINTRUST_API_KEY\"],\n",
    "        base_url=\"https://api.braintrust.dev/v1/proxy\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def extract_frames_b64(video_path: str) -> List[str]:\n",
    "    base64_frames = []\n",
    "    count = 0\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    try:\n",
    "        while video_capture.isOpened() and count < NUM_FRAMES:\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, TARGET_DIMENSIONS)\n",
    "            success, encoded_img = cv2.imencode(\n",
    "                \".jpg\", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY]\n",
    "            )\n",
    "            if success:\n",
    "                b64_str = base64.b64encode(encoded_img).decode(\"utf-8\")\n",
    "                base64_frames.append(b64_str)\n",
    "            count += 1\n",
    "    finally:\n",
    "        # Ensure the capture is always released\n",
    "        video_capture.release()\n",
    "\n",
    "    return base64_frames\n",
    "\n",
    "\n",
    "def get_video_data(video_path: str, session: requests.Session) -> Optional[bytes]:\n",
    "    try:\n",
    "        if video_path.startswith(\"http\"):\n",
    "            response = session.get(video_path, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return response.content\n",
    "        else:\n",
    "            with open(video_path, \"rb\") as f:\n",
    "                return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving video data from {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data_subset() -> List[Dict[str, Any]]:\n",
    "    ds = load_dataset(\"yale-nlp/MMVU\", split=\"validation[:20]\")\n",
    "\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=RETRY_TOTAL,\n",
    "        backoff_factor=RETRY_BACKOFF,\n",
    "        status_forcelist=STATUS_FORCELIST,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    data_list = []\n",
    "    for row in ds:\n",
    "        question_type = row[\"question_type\"]\n",
    "        video_path = row[\"video\"]\n",
    "\n",
    "        frames_b64 = extract_frames_b64(video_path)\n",
    "        raw_video = get_video_data(video_path, session)\n",
    "\n",
    "        choices_data = (\n",
    "            row.get(\"choices\") if question_type == \"multiple-choice\" else None\n",
    "        )\n",
    "\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"input\": {\n",
    "                    \"frames_b64\": frames_b64,\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"question_type\": question_type,\n",
    "                    \"choices\": choices_data,\n",
    "                    \"video_attachment\": braintrust.Attachment(\n",
    "                        filename=os.path.basename(video_path),\n",
    "                        content_type=\"video/mp4\",\n",
    "                        data=raw_video,\n",
    "                    ),\n",
    "                },\n",
    "                \"expected\": {\"answer\": row[\"answer\"]},\n",
    "                \"metadata\": {\n",
    "                    \"subject\": row[\"metadata\"][\"subject\"],\n",
    "                    \"textbook\": row[\"metadata\"][\"textbook\"],\n",
    "                    \"question_type\": question_type,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    session.close()\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def video_qa(input_dict: Dict[str, Any]) -> str:\n",
    "    frames_b64 = input_dict[\"frames_b64\"]\n",
    "    question = input_dict[\"question\"]\n",
    "    question_type = input_dict.get(\"question_type\", \"open-ended\")\n",
    "    choices_data = input_dict.get(\"choices\")\n",
    "\n",
    "    content_blocks = [\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\", \"detail\": \"low\"},\n",
    "        }\n",
    "        for b64 in frames_b64\n",
    "    ]\n",
    "\n",
    "    if question_type == \"multiple-choice\" and choices_data:\n",
    "        if isinstance(choices_data, dict):\n",
    "            options_text = \"\\n\".join(\n",
    "                f\"{key}: {value}\" for key, value in choices_data.items()\n",
    "            )\n",
    "        else:\n",
    "            options_text = \"\\n\".join(\n",
    "                f\"{chr(65 + i)}: {option}\" for i, option in enumerate(choices_data)\n",
    "            )\n",
    "        prompt_text = (\n",
    "            f\"You just saw {NUM_FRAMES} frames from a video. Based on what you see, \"\n",
    "            f\"answer the following question: {question}.\\n\\n\"\n",
    "            f\"Here are your options:\\n{options_text}\\n\"\n",
    "            \"Choose the correct option in the format 'answer: X'. If uncertain, guess. You MUST pick something.\"\n",
    "        )\n",
    "    else:\n",
    "        prompt_text = (\n",
    "            f\"You just saw {NUM_FRAMES} frames from a video. \"\n",
    "            f\"Answer the following question: {question}.\\n\"\n",
    "            \"If uncertain, guess. Provide the best possible answer. You MUST answer to the best of your ability.\"\n",
    "        )\n",
    "\n",
    "    content_blocks.append({\"type\": \"text\", \"text\": prompt_text})\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        \"You are a helpful assistant. Provide an answer even if you are uncertain.\"\n",
    "                    ),\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": content_blocks},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(model=\"gpt-4o\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "judge_scorer = autoevals.LLMClassifier(\n",
    "    name=\"LLMJudge\",\n",
    "    prompt_template=(\n",
    "        \"You are a judge evaluating a model's ability to answer a question \"\n",
    "        f\"based on {NUM_FRAMES} frames in a video.\\n\\n\"\n",
    "        \"Model's answer:\\n{{output}}\\n\\n\"\n",
    "        \"Expected answer:\\n{{expected.answer}}\\n\\n\"\n",
    "        \"Is the model's answer correct? (Y/N)? Only Y or N.\"\n",
    "    ),\n",
    "    choice_scores={\"Y\": 1, \"N\": 0},\n",
    "    use_cot=True,\n",
    ")\n",
    "\n",
    "\n",
    "await braintrust.EvalAsync(\n",
    "    \"mmvu_eval_32images\",\n",
    "    data=load_data_subset,\n",
    "    task=video_qa,\n",
    "    scores=[judge_scorer],\n",
    "    metadata={\"model\": \"gpt-4o\"},\n",
    "    experiment_name=\"mmvu_eval_32images\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
