{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: requests in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (2.32.2)\n",
      "Requirement already satisfied: datasets in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: braintrust in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (0.0.182)\n",
      "Requirement already satisfied: autoevals in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (0.0.117)\n",
      "Requirement already satisfied: openai in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (1.40.8)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (3.10.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: GitPython in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (3.1.41)\n",
      "Requirement already satisfied: chevron in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (0.14.0)\n",
      "Requirement already satisfied: braintrust_core in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (0.0.58)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (1.2.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (1.0.0)\n",
      "Requirement already satisfied: sseclient-py in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (1.8.0)\n",
      "Requirement already satisfied: python-slugify in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (8.0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.1.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from braintrust) (4.12.2)\n",
      "Requirement already satisfied: levenshtein in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from autoevals) (0.25.1)\n",
      "Requirement already satisfied: jsonschema in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from autoevals) (4.21.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from GitPython->braintrust) (4.0.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from jsonschema->autoevals) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from jsonschema->autoevals) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from jsonschema->autoevals) (0.20.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from levenshtein->autoevals) (3.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from python-slugify->braintrust) (1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adrian/braintrust/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python requests datasets braintrust autoevals openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment mmvu_eval_32images-fb15e25a is running at https://www.braintrust.dev/app/braintrustdata.com/p/mmvu_eval_32images/experiments/mmvu_eval_32images-fb15e25a\n",
      "mmvu_eval_32images [experiment_name=mmvu_eval_32images] (data): 20it [00:00, 93937.38it/s]\n",
      "mmvu_eval_32images [experiment_name=mmvu_eval_32images] (tasks): 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "mmvu_eval_32images-fb15e25a compared to mmvu_eval_32images-04ae25b8:\n",
      "45.00% 'LLMJudge' score\n",
      "\n",
      "1739836712.14s start\n",
      "1739836729.72s end\n",
      "15.47s duration\n",
      "8.23s llm_duration\n",
      "2472.25tok prompt_tokens\n",
      "32.40tok completion_tokens\n",
      "2504.65tok total_tokens\n",
      "0.01$ estimated_cost\n",
      "\n",
      "See results for mmvu_eval_32images-fb15e25a at https://www.braintrust.dev/app/braintrustdata.com/p/mmvu_eval_32images/experiments/mmvu_eval_32images-fb15e25a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import braintrust\n",
    "import autoevals\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "NUM_FRAMES = 32\n",
    "TARGET_DIMENSIONS = (512, 512)\n",
    "JPEG_QUALITY = 80\n",
    "\n",
    "RETRY_TOTAL = 3\n",
    "RETRY_BACKOFF = 0.5\n",
    "STATUS_FORCELIST = [502, 503, 504]\n",
    "\n",
    "\n",
    "os.environ[\"BRAINTRUST_API_KEY\"] = \"API_KEY_HERE\"\n",
    "\n",
    "\n",
    "client = braintrust.wrap_openai(\n",
    "    OpenAI(\n",
    "        api_key=os.environ[\"BRAINTRUST_API_KEY\"],\n",
    "        base_url=\"https://api.braintrust.dev/v1/proxy\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def extract_frames_b64(video_path: str) -> List[str]:\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    base64_frames = []\n",
    "    count = 0\n",
    "\n",
    "    while video_capture.isOpened() and count < NUM_FRAMES:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, TARGET_DIMENSIONS)\n",
    "        success, encoded_img = cv2.imencode(\n",
    "            \".jpg\", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY]\n",
    "        )\n",
    "        if success:\n",
    "            b64_str = base64.b64encode(encoded_img).decode(\"utf-8\")\n",
    "            base64_frames.append(b64_str)\n",
    "        count += 1\n",
    "\n",
    "    video_capture.release()\n",
    "    return base64_frames\n",
    "\n",
    "\n",
    "def get_video_data(video_path: str, session: requests.Session) -> Optional[bytes]:\n",
    "    try:\n",
    "        if video_path.startswith(\"http\"):\n",
    "            response = session.get(video_path, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return response.content\n",
    "        else:\n",
    "            with open(video_path, \"rb\") as f:\n",
    "                return f.read()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data_subset() -> List[Dict[str, Any]]:\n",
    "    ds = load_dataset(\"yale-nlp/MMVU\", split=\"validation[:20]\")\n",
    "\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=RETRY_TOTAL,\n",
    "        backoff_factor=RETRY_BACKOFF,\n",
    "        status_forcelist=STATUS_FORCELIST,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    data_list = []\n",
    "    for row in ds:\n",
    "        question_type = row[\"question_type\"]\n",
    "        video_path = row[\"video\"]\n",
    "\n",
    "        frames_b64 = extract_frames_b64(video_path)\n",
    "        raw_video = get_video_data(video_path, session)\n",
    "\n",
    "        choices_data = (\n",
    "            row.get(\"choices\") if question_type == \"multiple-choice\" else None\n",
    "        )\n",
    "\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"input\": {\n",
    "                    \"frames_b64\": frames_b64,\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"question_type\": question_type,\n",
    "                    \"choices\": choices_data,\n",
    "                    \"video_attachment\": braintrust.Attachment(\n",
    "                        filename=os.path.basename(video_path),\n",
    "                        content_type=\"video/mp4\",\n",
    "                        data=raw_video,\n",
    "                    ),\n",
    "                },\n",
    "                \"expected\": {\"answer\": row[\"answer\"]},\n",
    "                \"metadata\": {\n",
    "                    \"subject\": row[\"metadata\"][\"subject\"],\n",
    "                    \"textbook\": row[\"metadata\"][\"textbook\"],\n",
    "                    \"question_type\": question_type,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    session.close()\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def video_qa(input_dict: Dict[str, Any]) -> str:\n",
    "    frames_b64 = input_dict[\"frames_b64\"]\n",
    "    question = input_dict[\"question\"]\n",
    "    question_type = input_dict.get(\"question_type\", \"open-ended\")\n",
    "    choices_data = input_dict.get(\"choices\")\n",
    "\n",
    "    content_blocks = [\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\", \"detail\": \"low\"},\n",
    "        }\n",
    "        for b64 in frames_b64\n",
    "    ]\n",
    "\n",
    "    if question_type == \"multiple-choice\" and choices_data:\n",
    "        if isinstance(choices_data, dict):\n",
    "            options_text = \"\\n\".join(\n",
    "                f\"{key}: {value}\" for key, value in choices_data.items()\n",
    "            )\n",
    "        else:\n",
    "            options_text = \"\\n\".join(\n",
    "                f\"{chr(65 + i)}: {option}\" for i, option in enumerate(choices_data)\n",
    "            )\n",
    "        prompt_text = (\n",
    "            f\"You just saw {NUM_FRAMES} frames from a video. Based on what you see, \"\n",
    "            f\"answer the following question: {question}.\\n\\n\"\n",
    "            f\"Here are your options:\\n{options_text}\\n\"\n",
    "            \"Choose the correct option in the format 'answer: X'. If uncertain, guess. You MUST pick something.\"\n",
    "        )\n",
    "    else:\n",
    "        prompt_text = (\n",
    "            f\"You just saw {NUM_FRAMES} frames from a video. \"\n",
    "            f\"Answer the following question: {question}.\\n\"\n",
    "            \"If uncertain, guess. Provide the best possible answer. You MUST answer to the best of your ability.\"\n",
    "        )\n",
    "\n",
    "    content_blocks.append({\"type\": \"text\", \"text\": prompt_text})\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        \"You are a helpful assistant. Provide an answer even if you are uncertain.\"\n",
    "                    ),\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": content_blocks},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(model=\"gpt-4o\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "judge_scorer = autoevals.LLMClassifier(\n",
    "    name=\"LLMJudge\",\n",
    "    prompt_template=(\n",
    "        \"You are a judge evaluating a model's ability to answer a question \"\n",
    "        f\"based on {NUM_FRAMES} frames in a video.\\n\\n\"\n",
    "        \"Model's answer:\\n{{output}}\\n\\n\"\n",
    "        \"Expected answer:\\n{{expected.answer}}\\n\\n\"\n",
    "        \"Is the model's answer correct? (Y/N)? Only Y or N.\"\n",
    "    ),\n",
    "    choice_scores={\"Y\": 1, \"N\": 0},\n",
    "    use_cot=True,\n",
    ")\n",
    "\n",
    "\n",
    "await braintrust.EvalAsync(\n",
    "    \"mmvu_eval_32images\",\n",
    "    data=load_data_subset,\n",
    "    task=video_qa,\n",
    "    scores=[judge_scorer],\n",
    "    metadata={\"model\": \"gpt-4o\"},\n",
    "    experiment_name=\"mmvu_eval_32images\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
