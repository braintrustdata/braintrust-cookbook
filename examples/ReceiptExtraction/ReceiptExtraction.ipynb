{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receipt Extraction\n",
    "\n",
    "Document extraction is a use case that is [near and dear to my heart](https://www.youtube.com/watch?v=hoBtFhZRxzw). The last time I dug deeply into it, there were not nearly as many models\n",
    "capable of solving for it as there are today. In honor of Pixtral and LLaMa3.2, I thought it would be fun to revisit it with the classic SROIE dataset.\n",
    "\n",
    "Let's jump right in!\n",
    "\n",
    "## Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autoevals in ./.venv/lib/python3.12/site-packages (0.0.92)\n",
      "Requirement already satisfied: braintrust in ./.venv/lib/python3.12/site-packages (0.0.160)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.48.0)\n",
      "Requirement already satisfied: chevron in ./.venv/lib/python3.12/site-packages (from autoevals) (0.14.0)\n",
      "Requirement already satisfied: levenshtein in ./.venv/lib/python3.12/site-packages (from autoevals) (0.26.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from autoevals) (6.0.2)\n",
      "Requirement already satisfied: braintrust-core in ./.venv/lib/python3.12/site-packages (from autoevals) (0.0.54)\n",
      "Requirement already satisfied: jsonschema in ./.venv/lib/python3.12/site-packages (from autoevals) (4.23.0)\n",
      "Requirement already satisfied: GitPython in ./.venv/lib/python3.12/site-packages (from braintrust) (3.1.43)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from braintrust) (4.66.5)\n",
      "Requirement already satisfied: exceptiongroup==1.2.0 in ./.venv/lib/python3.12/site-packages (from braintrust) (1.2.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (from braintrust) (1.0.1)\n",
      "Requirement already satisfied: sseclient-py in ./.venv/lib/python3.12/site-packages (from braintrust) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.12/site-packages (from GitPython->braintrust) (4.0.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema->autoevals) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema->autoevals) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema->autoevals) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema->autoevals) (0.20.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in ./.venv/lib/python3.12/site-packages (from levenshtein->autoevals) (3.10.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autoevals braintrust requests openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LLM clients\n",
    "\n",
    "We'll use OpenAI's GPT-4o, LLaMa 3.2 11B and 90B, and Pixtral 12B with a bunch of test cases from SROIE and see how they perform. You can access each of these models\n",
    "behind the vanilla OpenAI client using Braintrust's proxy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import braintrust\n",
    "import openai\n",
    "\n",
    "client = braintrust.wrap_openai(\n",
    "    openai.AsyncOpenAI(\n",
    "        api_key=os.environ[\"BRAINTRUST_API_KEY\"],\n",
    "        base_url=\"http://localhost:8000/v1/proxy\",\n",
    "        # base_url=\"https://api.braintrust.dev/v1/proxy\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data and sanity testing it\n",
    "\n",
    "The [zzzDavid/ICDAR-2019-SROIE](https://github.com/zzzDavid/ICDAR-2019-SROIE/tree/master) repo has neatly organized the data for us. The files are enumerated in a 3 digit convention and for each image (e.g. 002.jpg), there is a corresponding\n",
    "file (e.g. 002.json) with the key value pairs. There are a few different ways we could test the models:\n",
    "\n",
    "- Ask each model to extract values for specific keys\n",
    "- Ask each model to generate a value for each of a set of keys\n",
    "- Ask the model to extract all keys and values from the receipt\n",
    "\n",
    "To keep things simple, we'll go with the first option, but it would be interesting to do each and see how that affects the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'INDAH GIFT & HOME DECO',\n",
       " 'date': '19/10/2018',\n",
       " 'address': '27, JALAN DEDAP 13, TAMAN JOHOR JAYA, 81100 JOHOR BAHRU, JOHOR.',\n",
       " 'total': '60.30'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "indices = [str(i).zfill(3) for i in range(100)]\n",
    "\n",
    "\n",
    "def load_receipt(index):\n",
    "    img_path = f\"https://raw.githubusercontent.com/zzzDavid/ICDAR-2019-SROIE/refs/heads/master/data/img/{index}.jpg\"\n",
    "    json_path = f\"https://raw.githubusercontent.com/zzzDavid/ICDAR-2019-SROIE/refs/heads/master/data/key/{index}.json\"\n",
    "\n",
    "    json_response = requests.get(json_path).json()\n",
    "    return json_response, img_path\n",
    "\n",
    "\n",
    "fields, img_path = load_receipt(\"001\")\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![receipt](https://raw.githubusercontent.com/zzzDavid/ICDAR-2019-SROIE/refs/heads/master/data/img/001.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model:  gpt-4o\n",
      "INDAH GIFT & HOME DECO\n",
      "\n",
      "\n",
      "Running model:  gpt-4o-mini\n",
      "INDAH GIFT & HOME DECO\n",
      "\n",
      "\n",
      "Running model:  meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo\n",
      "60.30\n",
      "\n",
      "\n",
      "Running model:  meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\n",
      "INDAH GIFT & HOME DECO\n",
      "\n",
      "\n",
      "Running model:  pixtral-12b-2409\n",
      "tan woon yann\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODELS = [\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo\",\n",
    "    \"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",\n",
    "    \"pixtral-12b-2409\",\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"Extract the field '{key}' from the provided receipt. Return the extracted\n",
    "value, and nothing else. For example, if the field is 'Total' and the value is '100',\n",
    "you should just return '100'. If the field is not present, return null.\n",
    "\n",
    "Do not decorate the output with any explanation, or markdown. Just return the extracted value.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@braintrust.traced\n",
    "async def extract_value(model, key, img_path):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT.format(key=key)},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": img_path}}]},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "for model in MODELS:\n",
    "    print(\"Running model: \", model)\n",
    "    print(await extract_value(model, \"company\", img_path))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the evaluation\n",
    "\n",
    "Now that we were able to perform a basic sanity test, let's run an evaluation! We'll use the `Levenshtein` and `Factuality` scorers to assess performance.\n",
    "`Levenshtein` is heuristic and will tell us how closely the actual and expected strings match. Assuming some of the models will occasionally spit out superfluous\n",
    "explanation text, `Factuality`, which is LLM based, should be able to still give us an accuracy measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Receipt Extraction - gpt-4o-5084b768 is running at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20gpt-4o-5084b768\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - gpt-4o] (data): 80it [00:00, 160011.60it/s]\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - gpt-4o] (tasks): 100%|██████████| 80/80 [00:36<00:00,  2.20it/s]\n",
      "Experiment Receipt Extraction - gpt-4o-mini is running at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20gpt-4o-mini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "81.25% 'Factuality'  score\n",
      "87.85% 'Levenshtein' score\n",
      "\n",
      "4.28s duration\n",
      "4.27s llm_duration\n",
      "1002tok prompt_tokens\n",
      "11.71tok completion_tokens\n",
      "1013.71tok total_tokens\n",
      "0.01$ estimated_cost\n",
      "\n",
      "See results for Receipt Extraction - gpt-4o-5084b768 at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20gpt-4o-5084b768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Receipt Extraction [experiment_name=Receipt Extraction - gpt-4o-mini] (data): 80it [00:00, 284842.38it/s]\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - gpt-4o-mini] (tasks): 100%|██████████| 80/80 [00:11<00:00,  6.73it/s]\n",
      "Experiment Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo is running at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20meta-llama%2FLlama-3.2-11B-Vision-Instruct-Turbo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "Receipt Extraction - gpt-4o-mini compared to Receipt Extraction - gpt-4o-5084b768:\n",
      "82.75% (+01.50%) 'Factuality'  score\t(6 improvements, 6 regressions)\n",
      "91.42% (+03.57%) 'Levenshtein' score\t(17 improvements, 5 regressions)\n",
      "\n",
      "3.65s (-62.78%) 'duration'         \t(44 improvements, 31 regressions)\n",
      "3.64s (-62.81%) 'llm_duration'     \t(44 improvements, 31 regressions)\n",
      "30685.30tok (+2968330.00%) 'prompt_tokens'    \t(0 improvements, 80 regressions)\n",
      "13.14tok (+142.50%) 'completion_tokens'\t(4 improvements, 13 regressions)\n",
      "30698.44tok (+2968472.50%) 'total_tokens'     \t(0 improvements, 80 regressions)\n",
      "0.00$ (-00.06%) 'estimated_cost'   \t(75 improvements, 0 regressions)\n",
      "\n",
      "See results for Receipt Extraction - gpt-4o-mini at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Receipt Extraction [experiment_name=Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo] (data): 80it [00:00, 220462.76it/s]\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo] (tasks): 100%|██████████| 80/80 [00:13<00:00,  5.96it/s]\n",
      "Experiment Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo is running at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20meta-llama%2FLlama-3.2-90B-Vision-Instruct-Turbo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo compared to Receipt Extraction - gpt-4o-mini:\n",
      "50.04% (-41.37%) 'Levenshtein' score\t(3 improvements, 47 regressions)\n",
      "51.50% (-31.25%) 'Factuality'  score\t(6 improvements, 31 regressions)\n",
      "\n",
      "5.82s (+217.45%) 'duration'         \t(11 improvements, 64 regressions)\n",
      "5.81s (+217.49%) 'llm_duration'     \t(11 improvements, 64 regressions)\n",
      "89tok (-3059630.00%) 'prompt_tokens'    \t(80 improvements, 0 regressions)\n",
      "10.15tok (-298.75%) 'completion_tokens'\t(29 improvements, 49 regressions)\n",
      "99.15tok (-3059928.75%) 'total_tokens'     \t(80 improvements, 0 regressions)\n",
      "0.00$ (-00.48%) 'estimated_cost'   \t(75 improvements, 0 regressions)\n",
      "\n",
      "See results for Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20meta-llama%2FLlama-3.2-11B-Vision-Instruct-Turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Receipt Extraction [experiment_name=Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo] (data): 80it [00:00, 163600.35it/s]\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo] (tasks): 100%|██████████| 80/80 [00:16<00:00,  4.71it/s]\n",
      "Experiment Receipt Extraction - pixtral-12b-2409 is running at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20pixtral-12b-2409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo compared to Receipt Extraction - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo:\n",
      "79.75% (+28.25%) 'Factuality'  score\t(31 improvements, 8 regressions)\n",
      "80.10% (+30.05%) 'Levenshtein' score\t(40 improvements, 9 regressions)\n",
      "\n",
      "6.99s (+116.80%) 'duration'         \t(27 improvements, 48 regressions)\n",
      "6.98s (+116.78%) 'llm_duration'     \t(27 improvements, 48 regressions)\n",
      "89tok (-) 'prompt_tokens'    \t(0 improvements, 0 regressions)\n",
      "15.20tok (+505.00%) 'completion_tokens'\t(13 improvements, 35 regressions)\n",
      "104.20tok (+505.00%) 'total_tokens'     \t(13 improvements, 35 regressions)\n",
      "0.00$ (+00.01%) 'estimated_cost'   \t(0 improvements, 75 regressions)\n",
      "\n",
      "See results for Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20meta-llama%2FLlama-3.2-90B-Vision-Instruct-Turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Receipt Extraction [experiment_name=Receipt Extraction - pixtral-12b-2409] (data): 80it [00:00, 280790.23it/s]\n",
      "Receipt Extraction [experiment_name=Receipt Extraction - pixtral-12b-2409] (tasks): 100%|██████████| 80/80 [01:09<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "Receipt Extraction - pixtral-12b-2409 compared to Receipt Extraction - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo:\n",
      "75.23% (-04.87%) 'Levenshtein' score\t(15 improvements, 27 regressions)\n",
      "68.00% (-11.75%) 'Factuality'  score\t(12 improvements, 16 regressions)\n",
      "\n",
      "35.77s (+2878.14%) 'duration'         \t(24 improvements, 51 regressions)\n",
      "35.76s (+2878.14%) 'llm_duration'     \t(25 improvements, 50 regressions)\n",
      "1949.35tok (+186035.00%) 'prompt_tokens'    \t(0 improvements, 80 regressions)\n",
      "20.51tok (+531.25%) 'completion_tokens'\t(25 improvements, 52 regressions)\n",
      "1969.86tok (+186566.25%) 'total_tokens'     \t(0 improvements, 80 regressions)\n",
      "0.00$ (+00.02%) 'estimated_cost'   \t(0 improvements, 73 regressions)\n",
      "\n",
      "See results for Receipt Extraction - pixtral-12b-2409 at http://localhost:3000/app/braintrustdata.com/p/Receipt%20Extraction/experiments/Receipt%20Extraction%20-%20pixtral-12b-2409\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval\n",
    "\n",
    "from autoevals import Factuality, Levenshtein\n",
    "\n",
    "NUM_RECEIPTS = 20\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"key\": key,\n",
    "            \"img_path\": img_path,\n",
    "        },\n",
    "        \"expected\": value,\n",
    "        \"metadata\": {\n",
    "            \"idx\": idx,\n",
    "        },\n",
    "    }\n",
    "    for idx, (fields, img_path) in [(idx, load_receipt(idx)) for idx in indices[:NUM_RECEIPTS]]\n",
    "    for key, value in fields.items()\n",
    "]\n",
    "\n",
    "for model in MODELS:\n",
    "\n",
    "    async def task(input):\n",
    "        return await extract_value(model, input[\"key\"], input[\"img_path\"])\n",
    "\n",
    "    await Eval(\n",
    "        \"Receipt Extraction\",\n",
    "        data=data,\n",
    "        task=task,\n",
    "        scores=[Levenshtein, Factuality],\n",
    "        experiment_name=f\"Receipt Extraction - {model}\",\n",
    "        metadata={\"model\": model},\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
