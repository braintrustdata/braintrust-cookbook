{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS part 1: Retrieval\n",
    "\n",
    "[RAGAS](https://github.com/explodinggradients/ragas) is a popular framework for evaluating Retrieval Augmented Generation (RAG) applications. It's been a longstanding\n",
    "popular request to add these metrics to [`autoevals`](https://github.com/braintrustdata/autoevals), so I thought I'd take the opportunity to audit and port them, and\n",
    "share the process openly. Hopefully it serves as a deeper window into evaluating RAG with RAGAS-style analysis, and also a guide on how to write your own evaluators.\n",
    "\n",
    "We'll use the [Coda Help Desk](https://www.braintrustdata.com/docs/cookbook/CodaHelpDesk) data to benchmark RAGAS evaluators, observe issues, and then tweak and port them\n",
    "into autoevals. Although this cookbook is implemented in Python, the evaluators are now available in both Python and Typescript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U autoevals[scipy] braintrust requests openai lancedb markdownify ragas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the purpose of starring documents in Coda?\n",
      "Answer: Starring docs in Coda helps to mark documents of personal importance and organizes them in a section called My Shortcuts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankur/projects/braintrust/cookbook/content/examples/Ragas/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    ragas_data_list = json.load(f)\n",
    "\n",
    "ragas_ds = Dataset.from_list(ragas_data_list)\n",
    "print(\"Question:\", ragas_ds[0][\"question\"])\n",
    "print(\"Answer:\", ragas_ds[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselining the RAGAS retrieval metrics\n",
    "\n",
    "RAGAS splits metrics into two buckets: generation and retrieval.\n",
    "\n",
    "![RAGAS framework](https://docs.ragas.io/en/stable/_static/imgs/component-wise-metrics.png)\n",
    "\n",
    "We'll start by working through retrieval metrics:\n",
    "\n",
    "- `context_precision`\n",
    "- `context_relevancy`\n",
    "- `context_recall`\n",
    "- `context_entity_recall`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:06<00:00, 11.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of starring documents in C...</td>\n",
       "      <td>Starring docs in Coda helps to mark documents ...</td>\n",
       "      <td>Starring docs in Coda helps to mark documents ...</td>\n",
       "      <td>[Not all Coda docs are used in the same way. Y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can starring docs in Coda help you?</td>\n",
       "      <td>Starring docs in Coda helps to mark documents ...</td>\n",
       "      <td>Starring docs in Coda helps to mark documents ...</td>\n",
       "      <td>[Not all Coda docs are used in the same way. Y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What happens when you star a doc in Coda?</td>\n",
       "      <td>After you star a doc in Coda, it will appear i...</td>\n",
       "      <td>After you star a doc in Coda, it will appear i...</td>\n",
       "      <td>[Not all Coda docs are used in the same way. Y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where do starred docs go after you star them i...</td>\n",
       "      <td>After you star a doc in Coda, it will appear i...</td>\n",
       "      <td>After you star a doc in Coda, it will appear i...</td>\n",
       "      <td>[Not all Coda docs are used in the same way. Y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can starred docs from different workspaces be ...</td>\n",
       "      <td>Yes, all starred docs, even from multiple diff...</td>\n",
       "      <td>Yes, all starred docs, even from multiple diff...</td>\n",
       "      <td>[Not all Coda docs are used in the same way. Y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of starring documents in C...   \n",
       "1            How can starring docs in Coda help you?   \n",
       "2          What happens when you star a doc in Coda?   \n",
       "3  Where do starred docs go after you star them i...   \n",
       "4  Can starred docs from different workspaces be ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Starring docs in Coda helps to mark documents ...   \n",
       "1  Starring docs in Coda helps to mark documents ...   \n",
       "2  After you star a doc in Coda, it will appear i...   \n",
       "3  After you star a doc in Coda, it will appear i...   \n",
       "4  Yes, all starred docs, even from multiple diff...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Starring docs in Coda helps to mark documents ...   \n",
       "1  Starring docs in Coda helps to mark documents ...   \n",
       "2  After you star a doc in Coda, it will appear i...   \n",
       "3  After you star a doc in Coda, it will appear i...   \n",
       "4  Yes, all starred docs, even from multiple diff...   \n",
       "\n",
       "                                            contexts  context_precision  \\\n",
       "0  [Not all Coda docs are used in the same way. Y...                1.0   \n",
       "1  [Not all Coda docs are used in the same way. Y...                1.0   \n",
       "2  [Not all Coda docs are used in the same way. Y...                1.0   \n",
       "3  [Not all Coda docs are used in the same way. Y...                1.0   \n",
       "4  [Not all Coda docs are used in the same way. Y...                1.0   \n",
       "\n",
       "   context_recall  context_entity_recall  context_relevancy  \n",
       "0             1.0               0.333333           0.555556  \n",
       "1             1.0               0.333333           0.555556  \n",
       "2             1.0               0.500000           0.555556  \n",
       "3             1.0               0.500000           0.222222  \n",
       "4             1.0               0.000000           0.111111  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_entity_recall,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    context_relevancy,\n",
    ")\n",
    "\n",
    "score = evaluate(\n",
    "    ragas_ds,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        context_entity_recall,\n",
    "        context_relevancy,\n",
    "    ],\n",
    ")\n",
    "score_df = score.to_pandas()\n",
    "score_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean context_entity_recall: 0.3649999980241667\n",
      "Mean context_relevancy: 0.3230158730158731\n"
     ]
    }
   ],
   "source": [
    "for key in [\"context_entity_recall\", \"context_relevancy\"]:\n",
    "    print(f\"Mean {key}:\", score_df[key].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring `context_precision` and `context_recall`\n",
    "\n",
    "In this next section, we're going to explore `context_precision` and `context_recall`, to understand why their performance is low, and try to improve them. We'll use example `4`, which has a low score for both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can starred docs from different workspaces be accessed in one place?',\n",
       " 'answer': 'Yes, all starred docs, even from multiple different workspaces, will live in the My Shortcuts section.',\n",
       " 'ground_truth': 'Yes, all starred docs, even from multiple different workspaces, will live in the My Shortcuts section.',\n",
       " 'contexts': [\"Not all Coda docs are used in the same way. You'll inevitably have a few that you use every week, and some that you'll only use once. This is where starred docs can help you stay organized.\\n\\n\\n\\nStarring docs is a great way to mark docs of personal importance. After you star a doc, it will live in a section on your doc list called **[My Shortcuts](https://coda.io/shortcuts)**. All starred docs, even from multiple different workspaces, will live in this section.\\n\\n\\n\\nStarring docs only saves them to your personal My Shortcuts. It doesn’t affect the view for others in your workspace. If you’re wanting to shortcut docs not just for yourself but also for others in your team or workspace, you’ll [use pinning](https://help.coda.io/en/articles/2865511-starred-pinned-docs) instead.\"]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ragas_data_list[4]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Entity Recall\n",
    "\n",
    "Let's grab the prompt from `context_entity_recall`, which helps extract entities from the ground truth answer the contexts, and take a look at what's happening under the hood:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a text, extract unique entities without repetition. Ensure you consider different forms or mentions of the same entity as a single entity.\n",
      "\n",
      "The output should be a well-formatted JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output JSON schema:\n",
      "```\n",
      "{\"type\": \"object\", \"properties\": {\"entities\": {\"title\": \"Entities\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"entities\"]}\n",
      "```\n",
      "\n",
      "Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\n",
      "\n",
      "Examples:\n",
      "\n",
      "text: \"The Eiffel Tower, located in Paris, France, is one of the most iconic landmarks globally.\\n            Millions of visitors are attracted to it each year for its breathtaking views of the city.\\n            Completed in 1889, it was constructed in time for the 1889 World's Fair.\"\n",
      "output: ```{\"entities\": [\"Eiffel Tower\", \"Paris\", \"France\", \"1889\", \"World's Fair\"]}```\n",
      "\n",
      "text: \"The Colosseum in Rome, also known as the Flavian Amphitheatre, stands as a monument to Roman architectural and engineering achievement.\\n            Construction began under Emperor Vespasian in AD 70 and was completed by his son Titus in AD 80.\\n            It could hold between 50,000 and 80,000 spectators who watched gladiatorial contests and public spectacles.\"\n",
      "output: ```{\"entities\": [\"Colosseum\", \"Rome\", \"Flavian Amphitheatre\", \"Vespasian\", \"AD 70\", \"Titus\", \"AD 80\"]}```\n",
      "\n",
      "text: \"The Great Wall of China, stretching over 21,196 kilometers from east to west, is a marvel of ancient defensive architecture.\\n            Built to protect against invasions from the north, its construction started as early as the 7th century BC.\\n            Today, it is a UNESCO World Heritage Site and a major tourist attraction.\"\n",
      "output: ```{\"entities\": [\"Great Wall of China\", \"21,196 kilometers\", \"7th century BC\", \"UNESCO World Heritage Site\"]}```\n",
      "\n",
      "text: \"The Apollo 11 mission, which launched on July 16, 1969, marked the first time humans landed on the Moon.\\n            Astronauts Neil Armstrong, Buzz Aldrin, and Michael Collins made history, with Armstrong being the first man to step on the lunar surface.\\n            This event was a significant milestone in space exploration.\"\n",
      "output: ```{\"entities\": [\"Apollo 11 mission\", \"July 16, 1969\", \"Moon\", \"Neil Armstrong\", \"Buzz Aldrin\", \"Michael Collins\"]}```\n",
      "\n",
      "Your actual task:\n",
      "\n",
      "text: Not all Coda docs are used in the same way. You'll inevitably have a few that you use every week, and some that you'll only use once. This is where starred docs can help you stay organized.\n",
      "\n",
      "\n",
      "\n",
      "Starring docs is a great way to mark docs of personal importance. After you star a doc, it will live in a section on your doc list called **[My Shortcuts](https://coda.io/shortcuts)**. All starred docs, even from multiple different workspaces, will live in this section.\n",
      "\n",
      "\n",
      "\n",
      "Starring docs only saves them to your personal My Shortcuts. It doesn’t affect the view for others in your workspace. If you’re wanting to shortcut docs not just for yourself but also for others in your team or workspace, you’ll [use pinning](https://help.coda.io/en/articles/2865511-starred-pinned-docs) instead.\n",
      "output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics._context_entities_recall import TEXT_ENTITY_EXTRACTION as CONTEXT_ENTITIES_RECALL_TEMPLATE\n",
    "\n",
    "prompt = CONTEXT_ENTITIES_RECALL_TEMPLATE.format(text=\"\\n\".join(example[\"contexts\"]))\n",
    "print(prompt.prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```{\"entities\": [\"Coda docs\", \"My Shortcuts\", \"workspaces\", \"section\", \"starred docs\", \"view\", \"others\", \"workspace\", \"team\", \"pinning\"]}```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "RAGAS_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "# We'll use the Braintrust proxy so that everything is cached.\n",
    "client = openai.AsyncOpenAI(\n",
    "    base_url=\"https://braintrustproxy.com/v1\",\n",
    "    default_headers={\"x-bt-use-cache\": \"always\"},\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\", \"Your OPENAI_API_KEY here\"),\n",
    ")\n",
    "\n",
    "\n",
    "resp = await client.chat.completions.create(\n",
    "    model=RAGAS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt.prompt_str}],\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```{\"entities\": [\"starred docs\", \"multiple different workspaces\", \"My Shortcuts section\"]}```\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (\n",
    "        await client.chat.completions.create(\n",
    "            model=RAGAS_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": CONTEXT_ENTITIES_RECALL_TEMPLATE.format(text=example[\"ground_truth\"]).prompt_str,\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, only the string `\"starred docs\"` is in both sets, but `multiple different workspaces` and `My Shortcuts section` appears to be covered as well. Let's see if the list comparison in `autoevals` returns\n",
    "a better result.\n",
    "\n",
    "#### Using a better list overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(name='ListContains',\n",
      "      score=0.8800621780550074,\n",
      "      metadata={'lowest_distances': [0.15267817386741356,\n",
      "                                     0.2071352919675643,\n",
      "                                     0.0],\n",
      "                'pairs': [('My Shortcuts',\n",
      "                           'My Shortcuts section',\n",
      "                           0.8473218261325864),\n",
      "                          ('workspaces',\n",
      "                           'multiple different workspaces',\n",
      "                           0.7928647080324357),\n",
      "                          ('starred docs', 'starred docs', 1.0)]},\n",
      "      error=None)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from autoevals.list import ListContains\n",
    "from autoevals.string import EmbeddingSimilarity\n",
    "\n",
    "pprint(\n",
    "    await ListContains(pairwise_scorer=EmbeddingSimilarity(), allow_extra_entities=True).eval_async(\n",
    "        output=[\n",
    "            \"Coda docs\",\n",
    "            \"My Shortcuts\",\n",
    "            \"workspaces\",\n",
    "            \"section\",\n",
    "            \"starred docs\",\n",
    "            \"view\",\n",
    "            \"others\",\n",
    "            \"workspace\",\n",
    "            \"team\",\n",
    "            \"pinning\",\n",
    "        ],\n",
    "        expected=[\"starred docs\", \"multiple different workspaces\", \"My Shortcuts section\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Relevancy\n",
    "\n",
    "Now let's look at context relevancy. We'll start by examining the prompt used to extract relevant sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please extract relevant sentences from the provided context that is absolutely required answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase \"Insufficient Information\".  While extracting candidate sentences you're not allowed to make any changes to sentences from given context.\n",
      "\n",
      "Your actual task:\n",
      "\n",
      "question: Can starred docs from different workspaces be accessed in one place?\n",
      "context: Not all Coda docs are used in the same way. You'll inevitably have a few that you use every week, and some that you'll only use once. This is where starred docs can help you stay organized.\n",
      "\n",
      "\n",
      "\n",
      "Starring docs is a great way to mark docs of personal importance. After you star a doc, it will live in a section on your doc list called **[My Shortcuts](https://coda.io/shortcuts)**. All starred docs, even from multiple different workspaces, will live in this section.\n",
      "\n",
      "\n",
      "\n",
      "Starring docs only saves them to your personal My Shortcuts. It doesn’t affect the view for others in your workspace. If you’re wanting to shortcut docs not just for yourself but also for others in your team or workspace, you’ll [use pinning](https://help.coda.io/en/articles/2865511-starred-pinned-docs) instead.\n",
      "candidate sentences: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics._context_relevancy import CONTEXT_RELEVANCE, sent_tokenize\n",
    "\n",
    "prompt = CONTEXT_RELEVANCE.format(question=example[\"question\"], context=\"\\n\".join(example[\"contexts\"]))\n",
    "print(prompt.prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All starred docs, even from multiple different workspaces, will live in this section.\n"
     ]
    }
   ],
   "source": [
    "resp = await client.chat.completions.create(\n",
    "    model=RAGAS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt.prompt_str}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, all starred docs, even from multiple different workspaces, will live in the My Shortcuts section.\n"
     ]
    }
   ],
   "source": [
    "# As a refresher, let's remember the answer\n",
    "print(example[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding chain of thought + function calling\n",
    "\n",
    "Interesting, it appears that at least the previous sentence (\"After you star a doc...My Shortcuts\" is needed to produce the final answer). Let's see if we can improve\n",
    "this metric by asking for Chain of Thought.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelevantSentence(sentence='Starring docs is a great way to mark docs of personal importance.', reasons=[]),\n",
      " RelevantSentence(sentence='After you star a doc, it will live in a section on your doc list called **[My Shortcuts](https://coda.io/shortcuts)**.', reasons=[]),\n",
      " RelevantSentence(sentence='All starred docs, even from multiple different workspaces, will live in this section.', reasons=[])]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class RelevantSentence(BaseModel):\n",
    "    sentence: str = Field(..., description=\"The selected sentence\")\n",
    "    reasons: List[str] = Field(\n",
    "        ..., description=\"Reasons why the sentence is relevant. Explain your thinking step by step.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class RelevantSentences(BaseModel):\n",
    "    sentences: List[RelevantSentence] = Field(..., description=\"List of referenced sentences\")\n",
    "\n",
    "\n",
    "response = await client.chat.completions.create(\n",
    "    model=RAGAS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt.prompt_str}],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"extract_sentences\",\n",
    "                \"description\": \"Extract relevant sentences from a given context\",\n",
    "                \"parameters\": RelevantSentences.schema(),\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_sentences\"}},\n",
    ")\n",
    "\n",
    "try:\n",
    "    sentences = RelevantSentences(**json.loads(response.choices[0].message.tool_calls[0].function.arguments))\n",
    "except:\n",
    "    print(\"Failed to parse. Skipping:\")\n",
    "    print(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "\n",
    "pprint(sentences.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting to Autoevals\n",
    "\n",
    "Much better. We've bundled these improvements into scoring functions in `autoevals`. If you're curious, you can find the\n",
    "implementations on [Github](https://github.com/braintrustdata/autoevals/blob/main/py/autoevals/ragas.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(name='ContextEntityRecall',\n",
      "      score=0.6952517120038902,\n",
      "      metadata={'context_entities': ['Coda docs',\n",
      "                                     'My Shortcuts',\n",
      "                                     'workspaces',\n",
      "                                     'pinning'],\n",
      "                'expected_entities': ['starred docs',\n",
      "                                      'multiple different workspaces',\n",
      "                                      'My Shortcuts section']},\n",
      "      error=None)\n"
     ]
    }
   ],
   "source": [
    "from autoevals.ragas import ContextEntityRecall\n",
    "\n",
    "pprint(\n",
    "    await ContextEntityRecall().eval_async(\n",
    "        output=example[\"answer\"], expected=example[\"ground_truth\"], context=example[\"contexts\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(name='ContextRelevancy',\n",
      "      score=0.7423076923076923,\n",
      "      metadata={'relevant_sentences': [{'reasons': [],\n",
      "                                        'sentence': 'Starring docs is a great '\n",
      "                                                    'way to mark docs of '\n",
      "                                                    'personal importance.'},\n",
      "                                       {'reasons': [],\n",
      "                                        'sentence': 'After you star a doc, it '\n",
      "                                                    'will live in a section on '\n",
      "                                                    'your doc list called '\n",
      "                                                    '**[My '\n",
      "                                                    'Shortcuts](https://coda.io/shortcuts)**.'},\n",
      "                                       {'reasons': [],\n",
      "                                        'sentence': 'All starred docs, even '\n",
      "                                                    'from multiple different '\n",
      "                                                    'workspaces, will live in '\n",
      "                                                    'this section.'},\n",
      "                                       {'reasons': [],\n",
      "                                        'sentence': 'Starring docs only saves '\n",
      "                                                    'them to your personal My '\n",
      "                                                    'Shortcuts.'},\n",
      "                                       {'reasons': [],\n",
      "                                        'sentence': 'It doesn’t affect the '\n",
      "                                                    'view for others in your '\n",
      "                                                    'workspace.'},\n",
      "                                       {'reasons': [],\n",
      "                                        'sentence': 'If you’re wanting to '\n",
      "                                                    'shortcut docs not just '\n",
      "                                                    'for yourself but also for '\n",
      "                                                    'others in your team or '\n",
      "                                                    'workspace, you’ll [use '\n",
      "                                                    'pinning](https://help.coda.io/en/articles/2865511-starred-pinned-docs) '\n",
      "                                                    'instead.'}]},\n",
      "      error=None)\n"
     ]
    }
   ],
   "source": [
    "from autoevals.ragas import ContextRelevancy\n",
    "\n",
    "pprint(\n",
    "    await ContextRelevancy().eval_async(\n",
    "        input=example[\"question\"],\n",
    "        output=example[\"answer\"],\n",
    "        expected=example[\"ground_truth\"],\n",
    "        context=example[\"contexts\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Eval\n",
    "\n",
    "Now that we have `Scorer`s for each metric, we can easily run an `Eval()` in Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment ragas-1712521002 is running at http://localhost:3000/app/braintrustdata.com/p/Ragas%20Retrieval/experiments/ragas-1712521002\n",
      "Ragas Retrieval (data): 20it [00:00, 7364.24it/s]\n",
      "Ragas Retrieval (tasks): 100%|██████████| 20/20 [00:07<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "See results for ragas-1712521002 at http://localhost:3000/app/braintrustdata.com/p/Ragas%20Retrieval/experiments/ragas-1712521002\n",
      "\n",
      "=========================SUMMARY=========================\n",
      "See results for ragas-1712521002 at http://localhost:3000/app/braintrustdata.com/p/Ragas%20Retrieval/experiments/ragas-1712521002\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval\n",
    "\n",
    "\n",
    "async def context_entites(input, output, expected, metadata):\n",
    "    return await ContextEntityRecall().eval_async(output=output, expected=expected, context=metadata[\"contexts\"])\n",
    "\n",
    "\n",
    "async def context_relevancy(input, output, expected, metadata):\n",
    "    return await ContextRelevancy().eval_async(\n",
    "        input=input, output=output, expected=expected, context=metadata[\"contexts\"]\n",
    "    )\n",
    "\n",
    "\n",
    "result = await Eval(\n",
    "    name=\"Ragas Retrieval\",\n",
    "    data=[\n",
    "        {\n",
    "            \"input\": {\"question\": x[\"question\"], \"ground_truth\": x[\"answer\"]},\n",
    "            \"expected\": x[\"answer\"],\n",
    "            \"metadata\": {\"contexts\": x[\"contexts\"]},\n",
    "        }\n",
    "        for x in ragas_data_list\n",
    "    ],\n",
    "    task=lambda input: input[\"ground_truth\"],\n",
    "    scores=[context_entites, context_relevancy],\n",
    ")\n",
    "\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, the new scores look much higher, especially `ContextEntitiesScorer`, which we'd expect to be close to `1` for this use case.\n",
    "\n",
    "![scores](./assets/new_scores.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further improvements\n",
    "\n",
    "We can also dig into individual examples, and see exactly the set of extracted/overlapping entities. As you can see, certain examples are clearly broken, as \"Eiffel Tower\"\n",
    "is not in the text.\n",
    "\n",
    "![overlapping entities](./assets/extracted_entities.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braintrust makes it easy to debug these kinds of issues. For example, we can open up the exact prompt that ran, and try to see if using GPT-4 returns better results.\n",
    "\n",
    "![Try fix](./assets/try_fix.gif)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
