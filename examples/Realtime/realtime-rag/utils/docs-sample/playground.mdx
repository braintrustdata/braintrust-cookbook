---
title: "Playground"
description: "Explore, compare, and evaluate prompts"
---

import Link from "fumadocs-core/link";
import { Code } from "lucide-react";

# Prompt playground

The prompt playground is a tool for exploring, comparing, and evaluating prompts. The playground
is deeply integrated within Braintrust, so you can easily to try out prompts with data from your
[datasets](/docs/guides/datasets).

The playground supports a wide range of models including the latest models from OpenAI, Anthropic,
Mistral, Google, Meta, and more deployed on first and third party infrastructure. You can also configure
it to talk to your own model endpoints and custom models, as long as they speak the OpenAI, Anthropic, or
Google protocol.

We're constantly working on improving the playground and adding new features. If you have any feedback or
feature requests, please [reach out](/contact) to us.

## Creating a playground

The playground organizes your work into sessions. A session is a saved and collaborative workspace
that includes one or more prompts and is linked to a dataset.

![Empty Playground](/docs/guides/playground/empty-playground.webp)

### Sharing playgrounds

Playgrounds are designed for collaboration and automatically synchronize in real-time.

![Sync Playground](/docs/guides/playground/sync-playground.gif)

To share a playground, simply copy the URL and send it to your collaborators. Your collaborators
must be members of your organization to see the session. You can invite users from the <Link href="/app/settings?subroute=team" target="_blank">settings</Link> page.

Playgrounds can also be shared publicly (read-only).

## Writing prompts

Each prompt includes a model (e.g. GPT-4 or Claude-2), a prompt string or messages (depending on the model),
and an optional set of parameters (e.g. temperature) to control the model's behavior. When click "Run" (or
the keyboard shortcut Cmd/Ctrl+Enter), each prompt runs in parallel and the results stream into the grid below.

### Without a dataset

By default, a playground is not linked to a dataset, and is self contained. This is similar to the behavior
on other playgrounds (e.g. OpenAI's). This mode is a useful way to explore and compare self-contained prompts.

### With a dataset

The real power of Braintrust comes from linking a playground to a dataset. You can link to an existing dataset
or create a new one from the dataset dropdown:

![Dataset dropdown](/docs/guides/playground/prompt-dataset-dropdown.webp)

Once you link a dataset, you will see a new row in the grid for each record in the dataset. You can reference the
data from each record in your prompt using the `input`, `expected`, and `metadata` variables. The playground uses
[mustache](https://mustache.github.io/) syntax for templating:

![Prompt with dataset](/docs/guides/playground/prompt-with-dataset.webp)

Each value can be arbitrarily complex JSON, e.g.

![Prompt with JSON data](/docs/guides/playground/prompt-with-dataset-json.webp)

### Multimodal prompts

You can also add images to your prompts by selecting the image icon in the input field. Images can be accessed via URLs, base64 encoded images as strings, or variables that contain an image.

![Multimodal prompt](/docs/guides/playground/multimodal-prompt.png)

### Referencing outputs

Each prompt can reference the output of other prompts in the session (e.g. `output_a`). This is useful for
validating outputs or chaining prompts together. For example, we can add a grading prompt to the previous example
to verify that the output matches an expected value:

![Prompt with output](/docs/guides/playground/prompt-with-output.webp)

### Exporting prompt code

The playground makes it easy to export your prompts as code that you can run through the [AI proxy](/docs/guides/proxy). Select the code icon (<Code className="inline size-3" />) next to any chat-based prompt to get code snippets in TypeScript, Python, or cURL.

<video className="border rounded-md" loop autoPlay muted poster="/docs/guides/playground/generate-code-snippet-poster.png">
  <source src="/docs/guides/playground/generate-code-snippet.mp4" type="video/mp4" />
</video>

The generated code includes all the prompt configuration, including the model, messages, and any additional parameters you've set.

## Custom models

To configure custom models, see the [Custom models](/docs/guides/proxy#custom-models) section of the proxy docs.
Endpoint configurations, like custom models, are automatically picked up by the playground.
